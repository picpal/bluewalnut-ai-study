"""
Phase 5 - ì˜ˆì œ 1: ìˆœì°¨ íŒŒì´í”„ë¼ì¸ (Sequential Pipeline)

ëª©í‘œ:
- LCEL íŒŒì´í”„ ì—°ì‚°ìë¡œ ì—¬ëŸ¬ ë‹¨ê³„ ì—°ê²°
- ê° ë‹¨ê³„ì˜ ì¶œë ¥ì´ ìë™ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ì˜ ì…ë ¥
- ê¸°ì‚¬ ìš”ì•½ â†’ ë²ˆì—­ â†’ í‚¤ì›Œë“œ ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
"""

import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda

# API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = "your-api-key-here"

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0
)

print("=" * 70)
print("Phase 5 - ì˜ˆì œ 1: ìˆœì°¨ íŒŒì´í”„ë¼ì¸")
print("=" * 70)

# ============================================================================
# 1ë‹¨ê³„: ê° ë‹¨ê³„ ì •ì˜
# ============================================================================

print("\n[1ë‹¨ê³„] ê° ì²˜ë¦¬ ë‹¨ê³„ ì •ì˜\n")

# 1ë‹¨ê³„: ìš”ì•½ ì²´ì¸
summarizer = (
    PromptTemplate.from_template(
        "ë‹¤ìŒ ì˜ë¬¸ ê¸°ì‚¬ë¥¼ 3ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{article}"
    )
    | llm
    | StrOutputParser()
)

print("âœ… summarizer ì²´ì¸ ìƒì„±")
print("   ì…ë ¥: {article}")
print("   ì²˜ë¦¬: ì˜ë¬¸ ê¸°ì‚¬ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½")
print("   ì¶œë ¥: str (ìš”ì•½ ê²°ê³¼)")

# 2ë‹¨ê³„: ë²ˆì—­ ì²´ì¸
translator = (
    PromptTemplate.from_template(
        "ë‹¤ìŒ ì˜ë¬¸ í…ìŠ¤íŠ¸ë¥¼ í•œê¸€ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”:\n\n{text}"
    )
    | llm
    | StrOutputParser()
)

print("\nâœ… translator ì²´ì¸ ìƒì„±")
print("   ì…ë ¥: {text}")
print("   ì²˜ë¦¬: ì˜ë¬¸ì„ í•œê¸€ë¡œ ë²ˆì—­")
print("   ì¶œë ¥: str (ë²ˆì—­ ê²°ê³¼)")

# 3ë‹¨ê³„: í‚¤ì›Œë“œ ì¶”ì¶œ ì²´ì¸
keyword_extractor = (
    PromptTemplate.from_template(
        "ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ 3ê°œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„):\n\n{text}"
    )
    | llm
    | StrOutputParser()
)

print("\nâœ… keyword_extractor ì²´ì¸ ìƒì„±")
print("   ì…ë ¥: {text}")
print("   ì²˜ë¦¬: í•µì‹¬ í‚¤ì›Œë“œ 3ê°œ ì¶”ì¶œ")
print("   ì¶œë ¥: str (í‚¤ì›Œë“œ ëª©ë¡)")

# ============================================================================
# 2ë‹¨ê³„: í‚¤ ë§¤í•‘ í•¨ìˆ˜ ì •ì˜
# ============================================================================

print("\n" + "=" * 70)
print("[2ë‹¨ê³„] í‚¤ ë§¤í•‘ í•¨ìˆ˜ ì •ì˜")
print("=" * 70)

print("""
ë¬¸ì œ:
- summarizerëŠ” {article}ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ
- translatorì™€ keyword_extractorëŠ” {text}ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ
- í•˜ì§€ë§Œ summarizerì˜ ì¶œë ¥ì€ ë‹¨ìˆœ ë¬¸ìì—´ (str)

í•´ê²°:
- RunnableLambdaë¡œ str â†’ {"text": str} ë³€í™˜
""")

def map_to_text(output: str) -> dict:
    """ë¬¸ìì—´ ì¶œë ¥ì„ {text: ...} ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
    return {"text": output}

print("âœ… map_to_text í•¨ìˆ˜ ì •ì˜")
print("   ì…ë ¥: str")
print("   ì¶œë ¥: {'text': str}")

# ============================================================================
# 3ë‹¨ê³„: ì „ì²´ ì›Œí¬í”Œë¡œìš° êµ¬ì„±
# ============================================================================

print("\n" + "=" * 70)
print("[3ë‹¨ê³„] ì „ì²´ ì›Œí¬í”Œë¡œìš° êµ¬ì„±")
print("=" * 70)

workflow = (
    summarizer                      # ì…ë ¥: {article} â†’ ì¶œë ¥: str
    | RunnableLambda(map_to_text)   # ì…ë ¥: str â†’ ì¶œë ¥: {text: str}
    | translator                    # ì…ë ¥: {text} â†’ ì¶œë ¥: str
    | RunnableLambda(map_to_text)   # ì…ë ¥: str â†’ ì¶œë ¥: {text: str}
    | keyword_extractor             # ì…ë ¥: {text} â†’ ì¶œë ¥: str
)

print("""
âœ… ì „ì²´ ì›Œí¬í”Œë¡œìš°:

    {article}
       â†“
  [summarizer] (ìš”ì•½)
       â†“
     str
       â†“
  [map_to_text] (í‚¤ ë§¤í•‘)
       â†“
   {text: str}
       â†“
  [translator] (ë²ˆì—­)
       â†“
     str
       â†“
  [map_to_text] (í‚¤ ë§¤í•‘)
       â†“
   {text: str}
       â†“
  [keyword_extractor] (í‚¤ì›Œë“œ)
       â†“
     str (ìµœì¢… ê²°ê³¼)
""")

# ============================================================================
# 4ë‹¨ê³„: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
# ============================================================================

print("=" * 70)
print("[4ë‹¨ê³„] ì›Œí¬í”Œë¡œìš° ì‹¤í–‰")
print("=" * 70)

# í…ŒìŠ¤íŠ¸ ë°ì´í„°: ì˜ë¬¸ ê¸°ì‚¬
article = """
Artificial Intelligence (AI) is revolutionizing the way we live and work.
From healthcare to finance, AI technologies are being integrated into various
sectors, enhancing efficiency and decision-making processes. Machine learning
algorithms can now analyze vast amounts of data in seconds, identifying patterns
that would take humans years to discover. However, ethical concerns about AI,
such as privacy and job displacement, continue to be debated by experts worldwide.
As we move forward, it is crucial to develop AI responsibly, ensuring it benefits
humanity as a whole.
"""

print("\nğŸ“„ ì…ë ¥ ê¸°ì‚¬ (ì›ë¬¸):")
print("-" * 70)
print(article.strip())
print("-" * 70)

print("\nâ³ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘...")
print()

# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
result = workflow.invoke({"article": article})

print("\n" + "=" * 70)
print("âœ… ìµœì¢… ê²°ê³¼")
print("=" * 70)
print(f"\nğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ: {result}")

# ============================================================================
# 5ë‹¨ê³„: ì¤‘ê°„ ë‹¨ê³„ë³„ ì‹¤í–‰ (ë””ë²„ê¹…ìš©)
# ============================================================================

print("\n" + "=" * 70)
print("[5ë‹¨ê³„] ì¤‘ê°„ ë‹¨ê³„ë³„ ì‹¤í–‰ (ë””ë²„ê¹…)")
print("=" * 70)

print("\n1ï¸âƒ£ 1ë‹¨ê³„: ìš”ì•½")
print("-" * 70)
summary = summarizer.invoke({"article": article})
print(f"ìš”ì•½ ê²°ê³¼:\n{summary}")

print("\n2ï¸âƒ£ 2ë‹¨ê³„: ë²ˆì—­")
print("-" * 70)
translation = translator.invoke({"text": summary})
print(f"ë²ˆì—­ ê²°ê³¼:\n{translation}")

print("\n3ï¸âƒ£ 3ë‹¨ê³„: í‚¤ì›Œë“œ ì¶”ì¶œ")
print("-" * 70)
keywords = keyword_extractor.invoke({"text": translation})
print(f"í‚¤ì›Œë“œ:\n{keywords}")

# ============================================================================
# í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸
# ============================================================================

print("\n" + "=" * 70)
print("ğŸ“š í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸")
print("=" * 70)

print("""
1ï¸âƒ£ LCEL íŒŒì´í”„ ì—°ì‚°ì (|)
   - ì™¼ìª½ ì¶œë ¥ì´ ì˜¤ë¥¸ìª½ ì…ë ¥ìœ¼ë¡œ ìë™ ì „ë‹¬
   - ì˜ˆ: step1 | step2 | step3

2ï¸âƒ£ ê° ë‹¨ê³„ëŠ” Runnable
   - PromptTemplate | LLM | OutputParser
   - ëª¨ë‘ .invoke() ë©”ì„œë“œ ì œê³µ

3ï¸âƒ£ í‚¤ ë§¤í•‘ ì²˜ë¦¬
   - RunnableLambdaë¡œ ì¶œë ¥ í˜•ì‹ ë³€í™˜
   - str â†’ {"text": str} ë³€í™˜ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ ì—°ê²°

4ï¸âƒ£ ìˆœì°¨ ì‹¤í–‰
   - ê° ë‹¨ê³„ê°€ ì´ì „ ë‹¨ê³„ ì™„ë£Œ í›„ ì‹¤í–‰
   - ë‹¨ê³„ë³„ ì˜ì¡´ì„±ì´ ëª…í™•

5ï¸âƒ£ ìë™ ë°ì´í„° íë¦„
   - ìˆ˜ë™ìœ¼ë¡œ ê²°ê³¼ ì „ë‹¬ ë¶ˆí•„ìš”
   - ì²´ì¸ì´ ìë™ìœ¼ë¡œ ì²˜ë¦¬
""")

# ============================================================================
# Phase 4ì™€ ë¹„êµ
# ============================================================================

print("\n" + "=" * 70)
print("ğŸ†š Phase 4 vs Phase 5")
print("=" * 70)

print("""
Phase 4 ë°©ì‹ (ìˆ˜ë™ ë£¨í”„):
```python
messages = [HumanMessage(content=article)]

# 1ë‹¨ê³„: ìš”ì•½
response1 = llm.invoke(messages)
summary = response1.content

# 2ë‹¨ê³„: ë²ˆì—­
messages.append(AIMessage(content=summary))
messages.append(HumanMessage(content="ë²ˆì—­í•´ì¤˜"))
response2 = llm.invoke(messages)
translation = response2.content

# 3ë‹¨ê³„: í‚¤ì›Œë“œ
messages.append(AIMessage(content=translation))
messages.append(HumanMessage(content="í‚¤ì›Œë“œ ì¶”ì¶œí•´ì¤˜"))
response3 = llm.invoke(messages)
keywords = response3.content
```

ë¬¸ì œì :
âŒ ê° ë‹¨ê³„ë¥¼ ìˆ˜ë™ìœ¼ë¡œ í˜¸ì¶œ
âŒ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ìˆ˜ë™ ê´€ë¦¬
âŒ ì½”ë“œê°€ ê¸¸ê³  ë°˜ë³µì 
âŒ ë‹¨ê³„ ì¶”ê°€ ì‹œ ì½”ë“œ ìˆ˜ì • ë§ìŒ

Phase 5 ë°©ì‹ (LCEL íŒŒì´í”„ë¼ì¸):
```python
workflow = summarizer | map_to_text | translator | map_to_text | keyword_extractor
result = workflow.invoke({"article": article})
```

ì¥ì :
âœ… í•œ ì¤„ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì •ì˜
âœ… ìë™ ë°ì´í„° ì „ë‹¬
âœ… ì½ê¸° ì‰½ê³  ìœ ì§€ë³´ìˆ˜ ìš©ì´
âœ… ë‹¨ê³„ ì¶”ê°€/ì œê±° ê°„ë‹¨ (íŒŒì´í”„ë§Œ ìˆ˜ì •)
""")

# ============================================================================
# ì›Œí¬í”Œë¡œìš° í™•ì¥
# ============================================================================

print("\n" + "=" * 70)
print("ğŸ”§ ì›Œí¬í”Œë¡œìš° í™•ì¥ ì˜ˆì‹œ")
print("=" * 70)

print("""
ê¸°ì¡´ ì›Œí¬í”Œë¡œìš°ì— ë‹¨ê³„ ì¶”ê°€ê°€ ì‰½ìŠµë‹ˆë‹¤:

1ï¸âƒ£ ê°ì • ë¶„ì„ ë‹¨ê³„ ì¶”ê°€:
sentiment_analyzer = PromptTemplate(...) | llm | StrOutputParser()

extended_workflow = (
    summarizer
    | map_to_text
    | translator
    | map_to_text
    | sentiment_analyzer  # ìƒˆ ë‹¨ê³„ ì¶”ê°€
    | map_to_text
    | keyword_extractor
)

2ï¸âƒ£ ì „ì²˜ë¦¬ ë‹¨ê³„ ì¶”ê°€:
cleaner = RunnableLambda(lambda x: x.strip())

workflow_with_preprocessing = (
    cleaner  # ë§¨ ì•ì— ì¶”ê°€
    | summarizer
    | map_to_text
    | translator
    | map_to_text
    | keyword_extractor
)

3ï¸âƒ£ í›„ì²˜ë¦¬ ë‹¨ê³„ ì¶”ê°€:
formatter = RunnableLambda(lambda x: f"í•µì‹¬ í‚¤ì›Œë“œ: {x}")

workflow_with_formatting = (
    summarizer
    | map_to_text
    | translator
    | map_to_text
    | keyword_extractor
    | formatter  # ë§¨ ë’¤ì— ì¶”ê°€
)

íŒŒì´í”„ ì—°ì‚°ì ë•ë¶„ì— ë‹¨ê³„ ì¶”ê°€ê°€ ë§¤ìš° ê°„ë‹¨í•©ë‹ˆë‹¤!
""")

# ============================================================================
# ë‹¤ìŒ ë‹¨ê³„
# ============================================================================

print("\n" + "=" * 70)
print("â¡ï¸  ë‹¤ìŒ ë‹¨ê³„")
print("=" * 70)

print("""
ì˜ˆì œ 2ì—ì„œëŠ”:
- ë³‘ë ¬ íŒŒì´í”„ë¼ì¸ (RunnableParallel)
- ë™ì‹œì— ì—¬ëŸ¬ ì‘ì—… ì‹¤í–‰
- ìš”ì•½ + ê°ì • ë¶„ì„ + í‚¤ì›Œë“œë¥¼ ë™ì‹œì— ì²˜ë¦¬

ì˜ˆì œ 1 (ìˆœì°¨):
    ì…ë ¥ â†’ [ë‹¨ê³„1] â†’ [ë‹¨ê³„2] â†’ [ë‹¨ê³„3] â†’ ì¶œë ¥

ì˜ˆì œ 2 (ë³‘ë ¬):
             â”Œâ†’ [ì‘ì—…1] â†’ ê²°ê³¼1
    ì…ë ¥ ----â”¼â†’ [ì‘ì—…2] â†’ ê²°ê³¼2
             â””â†’ [ì‘ì—…3] â†’ ê²°ê³¼3
""")

print("\n" + "=" * 70)
print("âœ… ì˜ˆì œ 1 ì™„ë£Œ!")
print("=" * 70)
