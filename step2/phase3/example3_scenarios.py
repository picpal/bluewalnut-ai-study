"""
Step 3 - ì˜ˆì œ 3: ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸

ëª©í‘œ:
- í•¨ìˆ˜ í˜¸ì¶œì´ í•„ìš”í•œ ì§ˆë¬¸ vs ë¶ˆí•„ìš”í•œ ì§ˆë¬¸
- LLMì˜ íŒë‹¨ ë¡œì§ ì´í•´
- ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ Function Calling ë™ì‘ í™•ì¸
"""

import os
from dotenv import load_dotenv
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

print("=" * 50)
print("ì˜ˆì œ 3: ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸")
print("=" * 50)
print()

# 1. í•¨ìˆ˜ ì •ì˜
def get_weather(city: str) -> str:
    """
    ì§€ì •ëœ ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

    Args:
        city: ë‚ ì”¨ë¥¼ ì¡°íšŒí•  ë„ì‹œ ì´ë¦„

    Returns:
        ë‚ ì”¨ ì •ë³´ ë¬¸ìì—´
    """
    weather_data = {
        "ì„œìš¸": "ë§‘ìŒ, ê¸°ì˜¨ 15ë„",
        "ë¶€ì‚°": "íë¦¼, ê¸°ì˜¨ 18ë„",
        "ì œì£¼": "ë¹„, ê¸°ì˜¨ 20ë„"
    }
    return weather_data.get(city, f"{city}ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

print("ğŸ“Œ 1. í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ: get_weather()")
print()

# 2. LLM ì„¤ì • ë° í•¨ìˆ˜ ë°”ì¸ë”©
llm = ChatAnthropic(
    model="claude-3-haiku-20240307",
    temperature=0
)

llm_with_tools = llm.bind_tools([get_weather])

print("ğŸ“Œ 2. LLM ì„¤ì • ë° í•¨ìˆ˜ ë°”ì¸ë”© ì™„ë£Œ")
print()

# 3. í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
scenarios = [
    {
        "query": "ì„œìš¸ì˜ ë‚ ì”¨ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
        "expected": "í•¨ìˆ˜ í˜¸ì¶œ í•„ìš”",
        "reason": "ì‹¤ì‹œê°„ ë‚ ì”¨ ì •ë³´ê°€ í•„ìš”í•˜ë¯€ë¡œ get_weather í˜¸ì¶œ"
    },
    {
        "query": "ë‚ ì”¨ê°€ ì¢‹ìœ¼ë©´ ë¬´ì—‡ì„ í•˜ë©´ ì¢‹ì„ê¹Œìš”?",
        "expected": "í•¨ìˆ˜ í˜¸ì¶œ ë¶ˆí•„ìš”",
        "reason": "ì¼ë°˜ì ì¸ ì¡°ì–¸ì´ë¯€ë¡œ LLMì´ ì§ì ‘ ë‹µë³€ ê°€ëŠ¥"
    },
    {
        "query": "ë¶€ì‚° ë‚ ì”¨ ì–´ë•Œ?",
        "expected": "í•¨ìˆ˜ í˜¸ì¶œ í•„ìš”",
        "reason": "ë¶€ì‚°ì˜ ì‹¤ì‹œê°„ ë‚ ì”¨ ì •ë³´ê°€ í•„ìš”"
    }
]

print(f"ğŸ“Œ 3. í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ({len(scenarios)}ê°œ)")
for i, scenario in enumerate(scenarios, 1):
    print(f"  [{i}] '{scenario['query']}'")
    print(f"      ì˜ˆìƒ: {scenario['expected']}")
    print(f"      ì´ìœ : {scenario['reason']}")
    print()

print("âš ï¸  ì´ì œ LLM APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.")
print(f"  ì´ í˜¸ì¶œ íšŸìˆ˜: {len(scenarios) * 2}íšŒ (ê° ì‹œë‚˜ë¦¬ì˜¤ë‹¹ ìµœëŒ€ 2íšŒ)")
print()

input("Enterë¥¼ ëˆŒëŸ¬ ê³„ì† ì§„í–‰í•˜ì„¸ìš”...")
print()

# 4. ì‹œë‚˜ë¦¬ì˜¤ë³„ ì‹¤í–‰
results = []

for i, scenario in enumerate(scenarios, 1):
    print("=" * 50)
    print(f"ğŸ“Œ ì‹œë‚˜ë¦¬ì˜¤ {i}: '{scenario['query']}'")
    print("=" * 50)
    print()

    # ì²« ë²ˆì§¸ í˜¸ì¶œ: tool_calls í™•ì¸
    print(f"[ì‹¤í–‰ ì¤‘... 1/2]")
    response = llm_with_tools.invoke([HumanMessage(content=scenario['query'])])
    print()

    # tool_calls í™•ì¸
    if response.tool_calls:
        print("âœ… íŒë‹¨: í•¨ìˆ˜ í˜¸ì¶œ í•„ìš”")
        tool_call = response.tool_calls[0]
        print(f"  í•¨ìˆ˜: {tool_call['name']}")
        print(f"  ë§¤ê°œë³€ìˆ˜: {tool_call['args']}")
        print()

        # í•¨ìˆ˜ ì‹¤í–‰
        function_result = get_weather(**tool_call['args'])
        print(f"  ì‹¤í–‰ ê²°ê³¼: '{function_result}'")
        print()

        # ë‘ ë²ˆì§¸ í˜¸ì¶œ: ìµœì¢… ì‘ë‹µ
        print(f"[ì‹¤í–‰ ì¤‘... 2/2]")
        messages = [
            HumanMessage(content=scenario['query']),
            AIMessage(content=response.content, tool_calls=response.tool_calls),
            ToolMessage(content=function_result, tool_call_id=tool_call['id'])
        ]
        final_response = llm_with_tools.invoke(messages)
        print()

        print(f"  ìµœì¢… ì‘ë‹µ: '{final_response.content}'")

        results.append({
            "query": scenario['query'],
            "tool_called": True,
            "function": tool_call['name'],
            "args": tool_call['args'],
            "function_result": function_result,
            "final_answer": final_response.content
        })
    else:
        print("âŒ íŒë‹¨: í•¨ìˆ˜ í˜¸ì¶œ ë¶ˆí•„ìš”")
        print(f"  ì§ì ‘ ì‘ë‹µ: '{response.content}'")

        results.append({
            "query": scenario['query'],
            "tool_called": False,
            "final_answer": response.content
        })

    print()

# 5. ì „ì²´ ê²°ê³¼ ìš”ì•½
print("=" * 50)
print("ğŸ“Œ ì „ì²´ ê²°ê³¼ ìš”ì•½")
print("=" * 50)
print()

for i, result in enumerate(results, 1):
    print(f"[{i}] '{result['query']}'")
    if result['tool_called']:
        print(f"    âœ… í•¨ìˆ˜ í˜¸ì¶œ: {result['function']}({result['args']})")
        print(f"    â†’ ê²°ê³¼: {result['function_result']}")
    else:
        print(f"    âŒ í•¨ìˆ˜ í˜¸ì¶œ ì—†ìŒ (LLM ì§ì ‘ ì‘ë‹µ)")
    print(f"    â†’ ìµœì¢… ë‹µë³€: '{result['final_answer']}'")
    print()

# 6. LLM íŒë‹¨ ë¶„ì„
print("=" * 50)
print("ğŸ“Œ LLM íŒë‹¨ ë¶„ì„")
print("=" * 50)
print()

tool_called_count = sum(1 for r in results if r['tool_called'])
print(f"âœ… í•¨ìˆ˜ í˜¸ì¶œí•œ ê²½ìš°: {tool_called_count}ê°œ")
print(f"âŒ í•¨ìˆ˜ í˜¸ì¶œ ì•ˆ í•œ ê²½ìš°: {len(results) - tool_called_count}ê°œ")
print()

print("ğŸ“Œ LLMì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ê¸°ì¤€:")
print("1. ì‹¤ì‹œê°„ ë°ì´í„°ê°€ í•„ìš”í•œ ê²½ìš°")
print("   ì˜ˆ: 'ì„œìš¸ì˜ ë‚ ì”¨ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”' â†’ get_weather('ì„œìš¸') í˜¸ì¶œ")
print()
print("2. í•¨ìˆ˜ë¡œ í•´ê²° ê°€ëŠ¥í•œ êµ¬ì²´ì  ì§ˆë¬¸")
print("   ì˜ˆ: 'ë¶€ì‚° ë‚ ì”¨ ì–´ë•Œ?' â†’ get_weather('ë¶€ì‚°') í˜¸ì¶œ")
print()
print("3. ì¼ë°˜ì ì¸ ì§€ì‹/ì¡°ì–¸ì€ LLMì´ ì§ì ‘ ì‘ë‹µ")
print("   ì˜ˆ: 'ë‚ ì”¨ê°€ ì¢‹ìœ¼ë©´ ë¬´ì—‡ì„ í•˜ë©´ ì¢‹ì„ê¹Œìš”?' â†’ ì§ì ‘ ì‘ë‹µ")
print()

print("=" * 50)
print("âœ… ì˜ˆì œ 3 ì™„ë£Œ!")
print()
print("í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸:")
print("1. LLMì€ ì§ˆë¬¸ì„ ë¶„ì„í•´ì„œ í•¨ìˆ˜ í˜¸ì¶œ ì—¬ë¶€ ìë™ íŒë‹¨")
print("2. ì‹¤ì‹œê°„ ë°ì´í„°ê°€ í•„ìš”í•˜ë©´ í•¨ìˆ˜ í˜¸ì¶œ")
print("3. ì¼ë°˜ ì§€ì‹ì€ LLMì´ ì§ì ‘ ì‘ë‹µ")
print("4. í•¨ìˆ˜ì˜ docstringê³¼ ë§¤ê°œë³€ìˆ˜ ì„¤ëª…ì´ íŒë‹¨ì— ì¤‘ìš”")
print("=" * 50)
