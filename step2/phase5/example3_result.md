# Phase 5 - ì˜ˆì œ 3: ìˆœì°¨ + ë³‘ë ¬ ì¡°í•© ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼

## ì‹¤í–‰ ì •ë³´

- **ì‹¤í–‰ ì‹œê°**: 2025-12-10
- **í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**: ì „ì²˜ë¦¬ â†’ ë³‘ë ¬ ë¶„ì„ â†’ ê²°ê³¼ í†µí•©
- **ì‚¬ìš© ëª¨ë¸**: claude-3-haiku-20240307
- **Temperature**: 0

---

## ì‹¤í–‰ ê²°ê³¼

### ì „ì²´ íë¦„

```
ì…ë ¥
  â†“
[ì „ì²˜ë¦¬] (ìˆœì°¨)
  â”œâ†’ clean_text: ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜
  â””â†’ extract_sentences: ë¬¸ì¥ ë¶„ë¦¬, ê°œìˆ˜ ì¹´ìš´íŠ¸
  â†“
              â”Œâ†’ summarizer (ìš”ì•½)
              â”œâ†’ sentiment_analyzer (ê°ì •)
[ë³‘ë ¬ ë¶„ì„]   â”œâ†’ topic_classifier (ì£¼ì œ)
              â”œâ†’ keyword_extractor (í‚¤ì›Œë“œ)
              â””â†’ RunnablePassthrough (ë©”íƒ€ë°ì´í„° ë³´ì¡´)
  â†“
[ê²°ê³¼ í†µí•©] (ìˆœì°¨)
  â”œâ†’ integrate_results: ë”•ì…”ë„ˆë¦¬ í†µí•©
  â””â†’ format_final_report: ë³´ê³ ì„œ í¬ë§·íŒ…
  â†“
ìµœì¢… ë³´ê³ ì„œ
```

### ì‹¤í–‰ ê²°ê³¼ ìƒì„¸

#### 1ë‹¨ê³„: ì „ì²˜ë¦¬ (ìˆœì°¨)

**ì…ë ¥:**
```
Artificial Intelligence (AI) is revolutionizing the way we live and work.
From healthcare to finance, AI technologies are being integrated into various
sectors, enhancing efficiency and decision-making processes...
```

**ì¶œë ¥:**
```
ğŸ§¹ í…ìŠ¤íŠ¸ ì •ì œ ì™„ë£Œ (ê¸¸ì´: 574 ë¬¸ì)
ğŸ“„ ë¬¸ì¥ ë¶„ë¦¬ ì™„ë£Œ (5ê°œ ë¬¸ì¥)

{
    "article": "artificial intelligence (ai) is revolutionizing...",
    "sentence_count": 5
}
```

#### 2ë‹¨ê³„: ë³‘ë ¬ ë¶„ì„

**4ê°œ ë¶„ì„ + ë©”íƒ€ë°ì´í„° ë³´ì¡´ ë™ì‹œ ì‹¤í–‰:**

1. **ìš”ì•½**: "AI is transforming various industries..."
2. **ê°ì •**: "ì¤‘ë¦½ì "
3. **ì£¼ì œ**: "Technology"
4. **í‚¤ì›Œë“œ**: "artificial intelligence, machine learning, ethical concerns"
5. **ë©”íƒ€ë°ì´í„°**: ì›ë³¸ ë°ì´í„° ë³´ì¡´

#### 3ë‹¨ê³„: ê²°ê³¼ í†µí•© (ìˆœì°¨)

**ìµœì¢… ë³´ê³ ì„œ:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     ğŸ“Š ê¸°ì‚¬ ë¶„ì„ ìµœì¢… ë³´ê³ ì„œ                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

ğŸ“ ìš”ì•½: AI is transforming various industries...
ğŸ˜Š ê°ì • ë¶„ì„: ì¤‘ë¦½ì 
ğŸ·ï¸  ì£¼ì œ ë¶„ë¥˜: Technology
ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ: artificial intelligence, machine learning, ethical concerns

ğŸ“ˆ ë©”íƒ€ë°ì´í„°:
- ì´ ë¬¸ì¥ ìˆ˜: 5ê°œ
- ê¸°ì‚¬ ê¸¸ì´: 574ì
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ìˆœì°¨ + ë³‘ë ¬ ì¡°í•© ë¶„ì„

### 1. ì™œ ì´ íŒ¨í„´ì´ ì‹¤ì „ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ”ê°€?

#### âœ… ì¥ì 

**1. íš¨ìœ¨ì„±ê³¼ êµ¬ì¡°ì˜ ê· í˜•**
```
ì „ì²˜ë¦¬ (ìˆœì°¨): ë°ì´í„° ì •ì œ, ê²€ì¦ (ì˜ì¡´ì„± ìˆìŒ)
    â†“
ë³‘ë ¬ ë¶„ì„: ë‹¤ì–‘í•œ ë¶„ì„ ë™ì‹œ ìˆ˜í–‰ (ë…ë¦½ì )
    â†“
í†µí•© (ìˆœì°¨): ê²°ê³¼ ê²°í•©, í¬ë§·íŒ… (ì˜ì¡´ì„± ìˆìŒ)
```

**2. ì„±ëŠ¥ ìµœì í™”**
- ë³‘ë ¬ ê°€ëŠ¥í•œ ë¶€ë¶„ë§Œ ë³‘ë ¬ë¡œ â†’ ìµœëŒ€ ì„±ëŠ¥
- ìˆœì°¨ í•„ìš”í•œ ë¶€ë¶„ì€ ìˆœì°¨ë¡œ â†’ ì•ˆì •ì„±

**3. ëª…í™•í•œ ë‹¨ê³„ êµ¬ë¶„**
- ì „ì²˜ë¦¬: ì…ë ¥ ì¤€ë¹„
- ë¶„ì„: í•µì‹¬ ì‘ì—…
- í†µí•©: ê²°ê³¼ ì •ë¦¬

### 2. RunnablePassthroughì˜ ì—­í• 

```python
parallel_analysis = RunnableParallel(
    summary=summarizer,
    sentiment=sentiment_analyzer,
    topic=topic_classifier,
    keywords=keyword_extractor,
    metadata=RunnablePassthrough()  # ì›ë³¸ ë°ì´í„° ë³´ì¡´
)
```

**ì™œ í•„ìš”í•œê°€?**
- ë³‘ë ¬ ë¶„ì„ ë‹¨ê³„ì—ì„œ ì›ë³¸ ë°ì´í„° ë³´ì¡´
- ë‚˜ì¤‘ì— ë©”íƒ€ë°ì´í„°ë¡œ í™œìš©
- ë°ì´í„° ì†ì‹¤ ë°©ì§€

**ì¶œë ¥ ì˜ˆ:**
```python
{
    "summary": "...",
    "sentiment": "...",
    "topic": "...",
    "keywords": "...",
    "metadata": {  # ì›ë³¸ ë³´ì¡´
        "article": "...",
        "sentence_count": 5
    }
}
```

### 3. ì „ì²´ ì›Œí¬í”Œë¡œìš° ì½”ë“œ

```python
complete_workflow = (
    preprocessing       # ìˆœì°¨: ì „ì²˜ë¦¬
    | parallel_analysis # ë³‘ë ¬: ë‹¤ì¤‘ ë¶„ì„
    | integration       # ìˆœì°¨: ê²°ê³¼ í†µí•©
)

result = complete_workflow.invoke({"article": article})
```

**íŠ¹ì§•:**
- 3ê°œ ì£¼ìš” ë‹¨ê³„ë¥¼ íŒŒì´í”„ë¡œ ì—°ê²°
- ê° ë‹¨ê³„ê°€ ëª…í™•í•˜ê²Œ ë¶„ë¦¬
- ì‰½ê²Œ í™•ì¥ ê°€ëŠ¥

---

## í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸

### 1. ìˆœì°¨ì™€ ë³‘ë ¬ì˜ ì ì ˆí•œ ì¡°í•©

#### ìˆœì°¨ê°€ í•„ìš”í•œ ê²½ìš°
```
ì „ì²˜ë¦¬:
- clean_text â†’ extract_sentences
- ì²« ë²ˆì§¸ ê²°ê³¼ê°€ ë‘ ë²ˆì§¸ ì…ë ¥ìœ¼ë¡œ í•„ìš”

í†µí•©:
- integrate_results â†’ format_final_report
- í†µí•©ëœ ë°ì´í„°ë¥¼ í¬ë§·íŒ…
```

#### ë³‘ë ¬ì´ ê°€ëŠ¥í•œ ê²½ìš°
```
ë¶„ì„:
- summarizer, sentiment_analyzer, topic_classifier, keyword_extractor
- ëª¨ë‘ ê°™ì€ ì…ë ¥(ì „ì²˜ë¦¬ëœ ê¸°ì‚¬)ì„ ë°›ìŒ
- ì„œë¡œì˜ ê²°ê³¼ë¥¼ í•„ìš”ë¡œ í•˜ì§€ ì•ŠìŒ
```

### 2. ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ ë°ì´í„° íë¦„

```python
# ì „ì²˜ë¦¬ ì¶œë ¥ (dict)
{"article": "...", "sentence_count": 5}
    â†“
# ë³‘ë ¬ ë¶„ì„ ì¶œë ¥ (dict)
{
    "summary": "...",
    "sentiment": "...",
    "topic": "...",
    "keywords": "...",
    "metadata": {"article": "...", "sentence_count": 5}
}
    â†“
# í†µí•© ì¶œë ¥ (dict)
{
    "summary": "...",
    "sentiment": "...",
    "topic": "...",
    "keywords": "...",
    "sentence_count": 5,
    "article_length": 574
}
```

**ì¥ì :**
- í‚¤ ì´ë¦„ìœ¼ë¡œ ë°ì´í„° ì¶”ì 
- ì¤‘ê°„ ê²°ê³¼ í™•ì¸ ìš©ì´
- ìœ ì—°í•œ ë°ì´í„° ê´€ë¦¬

### 3. ê° ë‹¨ê³„ì˜ ë…ë¦½ì  í…ŒìŠ¤íŠ¸

```python
# ì „ì²˜ë¦¬ë§Œ í…ŒìŠ¤íŠ¸
preprocessed = preprocessing.invoke({"article": article})
print(preprocessed)

# ë³‘ë ¬ ë¶„ì„ë§Œ í…ŒìŠ¤íŠ¸
analysis_results = parallel_analysis.invoke(preprocessed)
print(analysis_results)

# í†µí•©ë§Œ í…ŒìŠ¤íŠ¸
final_result = integration.invoke(analysis_results)
print(final_result)
```

**ì¥ì :**
- ë””ë²„ê¹…ì´ ì‰¬ì›€
- ë¬¸ì œ ë°œìƒ ì‹œ ì›ì¸ íŒŒì•… ìš©ì´
- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥

---

## ì‹¤ì „ í™œìš© íŒ¨í„´

### íŒ¨í„´ 1: ë°ì´í„° íŒŒì´í”„ë¼ì¸

```python
data_pipeline = (
    # ìˆœì°¨: ë°ì´í„° ìˆ˜ì§‘ ë° ê²€ì¦
    data_collector | validator

    # ë³‘ë ¬: ë‹¤ì–‘í•œ ë³€í™˜
    | RunnableParallel(
        normalized=normalizer,
        enriched=enricher,
        validated=quality_checker
    )

    # ìˆœì°¨: ì €ì¥
    | database_saver
)
```

### íŒ¨í„´ 2: ë¬¸ì„œ ì²˜ë¦¬ ì‹œìŠ¤í…œ

```python
document_pipeline = (
    # ìˆœì°¨: PDF ì¶”ì¶œ ë° ì •ì œ
    pdf_extractor | text_cleaner

    # ë³‘ë ¬: ë‹¤ì–‘í•œ ë¶„ì„
    | RunnableParallel(
        summary=summarizer,
        entities=entity_extractor,
        topics=topic_classifier,
        keywords=keyword_extractor
    )

    # ìˆœì°¨: ë³´ê³ ì„œ ìƒì„±
    | report_generator | email_sender
)
```

### íŒ¨í„´ 3: ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”

```python
ensemble_pipeline = (
    # ìˆœì°¨: ì „ì²˜ë¦¬
    preprocessor

    # ë³‘ë ¬: ì—¬ëŸ¬ ëª¨ë¸ ì‹¤í–‰
    | RunnableParallel(
        gpt4=gpt4_chain,
        claude=claude_chain,
        gemini=gemini_chain,
        original=RunnablePassthrough()  # ì›ë³¸ ë³´ì¡´
    )

    # ìˆœì°¨: ì•™ìƒë¸” ë° ìµœì¢… ì„ íƒ
    | ensemble_selector | postprocessor
)
```

---

## ì„±ëŠ¥ ë¶„ì„

### ë‹¨ê³„ë³„ ì†Œìš” ì‹œê°„ ì¶”ì •

```
ì „ì²˜ë¦¬: 0.01ì´ˆ (ë¡œì»¬ ì²˜ë¦¬)
  â†“
ë³‘ë ¬ ë¶„ì„: 3-5ì´ˆ (LLM API í˜¸ì¶œ, ë³‘ë ¬)
  â†“
í†µí•©: 0.01ì´ˆ (ë¡œì»¬ ì²˜ë¦¬)
  â†“
ì´ ì†Œìš” ì‹œê°„: ì•½ 3-5ì´ˆ
```

### ìˆœì°¨ë¡œë§Œ ì‹¤í–‰í–ˆë‹¤ë©´?

```
ì „ì²˜ë¦¬: 0.01ì´ˆ
  â†“
ìˆœì°¨ ë¶„ì„:
  - ìš”ì•½: 2ì´ˆ
  - ê°ì •: 2ì´ˆ
  - ì£¼ì œ: 2ì´ˆ
  - í‚¤ì›Œë“œ: 2ì´ˆ
  = ì´ 8ì´ˆ
  â†“
í†µí•©: 0.01ì´ˆ
  â†“
ì´ ì†Œìš” ì‹œê°„: ì•½ 8ì´ˆ

ì„±ëŠ¥ í–¥ìƒ: 8ì´ˆ / 4ì´ˆ = 2ë°°
```

---

## í™•ì¥ ë° ìµœì í™”

### 1. ì „ì²˜ë¦¬ ë‹¨ê³„ í™•ì¥

```python
preprocessing = (
    RunnableLambda(clean_text)
    | RunnableLambda(extract_sentences)
    | RunnableLambda(detect_language)      # ì¶”ê°€
    | RunnableLambda(spell_check)          # ì¶”ê°€
)
```

### 2. ë³‘ë ¬ ë¶„ì„ ì¶”ê°€

```python
parallel_analysis = RunnableParallel(
    summary=summarizer,
    sentiment=sentiment_analyzer,
    topic=topic_classifier,
    keywords=keyword_extractor,
    entities=entity_extractor,             # ì¶”ê°€
    translation=translator,                # ì¶”ê°€
    metadata=RunnablePassthrough()
)
```

### 3. ì¡°ê±´ë¶€ í†µí•©

```python
def smart_integration(results: dict) -> dict:
    """ê²°ê³¼ í’ˆì§ˆì— ë”°ë¼ ë‹¤ë¥¸ í†µí•© ì „ëµ ì‚¬ìš©"""
    if results['sentiment'] == 'ë¶€ì •ì ':
        # ë¶€ì •ì ì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
        return negative_handler(results)
    else:
        return standard_handler(results)

integration = (
    RunnableLambda(smart_integration)
    | RunnableLambda(format_final_report)
)
```

---

## ì—ëŸ¬ ì²˜ë¦¬ ì „ëµ

### 1. ì „ì²˜ë¦¬ ë‹¨ê³„ ì—ëŸ¬

```python
def safe_preprocess(data: dict) -> dict:
    try:
        return preprocess(data)
    except Exception as e:
        return {"error": str(e), "article": data.get("article", "")}

preprocessing = RunnableLambda(safe_preprocess)
```

### 2. ë³‘ë ¬ ë¶„ì„ ì—ëŸ¬ (ì¼ë¶€ ì‹¤íŒ¨ í—ˆìš©)

```python
def safe_analyze(analyzer, name):
    def analyze_with_fallback(data):
        try:
            return analyzer.invoke(data)
        except Exception as e:
            return f"[ë¶„ì„ ì‹¤íŒ¨: {str(e)}]"
    return RunnableLambda(analyze_with_fallback)

parallel_analysis = RunnableParallel(
    summary=safe_analyze(summarizer, "ìš”ì•½"),
    sentiment=safe_analyze(sentiment_analyzer, "ê°ì •"),
    # ...
)
```

---

## ë‹¤ìŒ ë‹¨ê³„

**ì˜ˆì œ 4: ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤**ì—ì„œëŠ”:
- ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§
- ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
- ë°ì´í„° ê²€ì¦ ë° í’ˆì§ˆ ì²´í¬
- `WorkflowMonitor` í´ë˜ìŠ¤ë¡œ ì‹¤í–‰ ì¶”ì 
- í”„ë¡œë•ì…˜ ìˆ˜ì¤€ êµ¬í˜„

---

## ìš”ì•½

### Phase 5 ì˜ˆì œ 3ì˜ í•µì‹¬

1. **ìˆœì°¨ + ë³‘ë ¬ ì¡°í•©**
   - ì „ì²˜ë¦¬ (ìˆœì°¨): ë°ì´í„° ì¤€ë¹„
   - ë¶„ì„ (ë³‘ë ¬): ë…ë¦½ì  ì‘ì—…
   - í†µí•© (ìˆœì°¨): ê²°ê³¼ ì •ë¦¬

2. **ì‹¤ì „ íŒ¨í„´**
   - ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” êµ¬ì¡°
   - íš¨ìœ¨ì„±ê³¼ êµ¬ì¡°ì˜ ê· í˜•
   - ëª…í™•í•œ ë‹¨ê³„ êµ¬ë¶„

3. **RunnablePassthrough**
   - ì›ë³¸ ë°ì´í„° ë³´ì¡´
   - ë©”íƒ€ë°ì´í„° ìœ ì§€
   - ë°ì´í„° ì†ì‹¤ ë°©ì§€

4. **í™•ì¥ ê°€ëŠ¥ì„±**
   - ê° ë‹¨ê³„ì— ì‘ì—… ì¶”ê°€ ìš©ì´
   - ë…ë¦½ì  í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
   - ìœ ì—°í•œ êµ¬ì¡°

**ì´ íŒ¨í„´ì€ í”„ë¡œë•ì…˜ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤!**
