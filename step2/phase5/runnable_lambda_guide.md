# RunnableLambda ì™„ë²½ ê°€ì´ë“œ

## ëª©ì°¨

1. [RunnableLambdaë€?](#runnablelambdaë€)
2. [ì™œ í•„ìš”í•œê°€?](#ì™œ-í•„ìš”í•œê°€)
3. [ê¸°ë³¸ ì‚¬ìš©ë²•](#ê¸°ë³¸-ì‚¬ìš©ë²•)
4. [ì£¼ìš” í™œìš© ì‚¬ë¡€](#ì£¼ìš”-í™œìš©-ì‚¬ë¡€)
5. [ì‹¤ì „ ì˜ˆì œ](#ì‹¤ì „-ì˜ˆì œ)
6. [ê³ ê¸‰ íŒ¨í„´](#ê³ ê¸‰-íŒ¨í„´)
7. [ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­](#ì„±ëŠ¥-ê³ ë ¤ì‚¬í•­)
8. [ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤](#ë² ìŠ¤íŠ¸-í”„ë™í‹°ìŠ¤)

---

## RunnableLambdaë€?

**ì¼ë°˜ Python í•¨ìˆ˜ë¥¼ LangChainì˜ `Runnable` ì¸í„°í˜ì´ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ë˜í¼(Wrapper)**

```python
from langchain_core.runnables import RunnableLambda

# ì¼ë°˜ Python í•¨ìˆ˜
def my_function(x):
    return x.upper()

# Runnableë¡œ ë³€í™˜
runnable_function = RunnableLambda(my_function)

# ì´ì œ ì²´ì¸ì—ì„œ ì‚¬ìš© ê°€ëŠ¥
chain = step1 | runnable_function | step2
```

### í•µì‹¬ ê°œë…

- **ë˜í¼ íŒ¨í„´**: ì¼ë°˜ í•¨ìˆ˜ë¥¼ LangChain ì²´ì¸ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ê°ìŒˆ
- **ì¸í„°í˜ì´ìŠ¤ í†µì¼**: ëª¨ë“  LangChain ì»´í¬ë„ŒíŠ¸ì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ë™ì‘
- **ì²´ì¸ì˜ ì ‘ì°©ì œ**: ì„œë¡œ ë‹¤ë¥¸ ì»´í¬ë„ŒíŠ¸ë¥¼ ì—°ê²°í•˜ëŠ” ì—­í• 

---

## ì™œ í•„ìš”í•œê°€?

### 1. Runnable ì¸í„°í˜ì´ìŠ¤ í†µì¼

LangChainì˜ ëª¨ë“  ì£¼ìš” ì»´í¬ë„ŒíŠ¸ëŠ” `Runnable` ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤:

```python
# ëª¨ë‘ Runnable ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
prompt.invoke(input)      # PromptTemplate
llm.invoke(input)         # ChatModel
parser.invoke(input)      # OutputParser

# ì¼ë°˜ í•¨ìˆ˜ëŠ” Runnableì´ ì•„ë‹˜
my_function(input)        # âŒ invoke() ë©”ì„œë“œ ì—†ìŒ

# RunnableLambdaë¡œ ë³€í™˜
runnable = RunnableLambda(my_function)
runnable.invoke(input)    # âœ… invoke() ë©”ì„œë“œ ì‚¬ìš© ê°€ëŠ¥
```

### 2. íŒŒì´í”„ ì—°ì‚°ì í˜¸í™˜ì„±

```python
# âŒ ì¼ë°˜ í•¨ìˆ˜ëŠ” íŒŒì´í”„ ì—°ì‚°ìì™€ í˜¸í™˜ ë¶ˆê°€
chain = prompt | llm | my_function | parser  # TypeError!

# âœ… RunnableLambdaëŠ” íŒŒì´í”„ ì—°ì‚°ìì™€ ì™„ë²½ í˜¸í™˜
chain = prompt | llm | RunnableLambda(my_function) | parser
```

### 3. ì¶”ê°€ ê¸°ëŠ¥ ì œê³µ

```python
runnable = RunnableLambda(my_function)

# ë‹¨ì¼ ì‹¤í–‰
result = runnable.invoke(input)

# ë°°ì¹˜ ì²˜ë¦¬
results = runnable.batch([input1, input2, input3])

# ìŠ¤íŠ¸ë¦¬ë° (ê°€ëŠ¥í•œ ê²½ìš°)
for chunk in runnable.stream(input):
    print(chunk)

# ë¹„ë™ê¸° ì‹¤í–‰
result = await runnable.ainvoke(input)
```

---

## ê¸°ë³¸ ì‚¬ìš©ë²•

### 1. í•¨ìˆ˜ ì •ì˜ ë°©ì‹

#### ë°©ë²• 1: ì¼ë°˜ í•¨ìˆ˜ ì •ì˜ í›„ ë˜í•‘

```python
def uppercase(text: str) -> str:
    """í…ìŠ¤íŠ¸ë¥¼ ëŒ€ë¬¸ìë¡œ ë³€í™˜"""
    return text.upper()

runnable = RunnableLambda(uppercase)
result = runnable.invoke("hello")  # "HELLO"
```

#### ë°©ë²• 2: ëŒë‹¤ í•¨ìˆ˜ ì§ì ‘ ì‚¬ìš©

```python
runnable = RunnableLambda(lambda x: x.upper())
result = runnable.invoke("hello")  # "HELLO"
```

#### ë°©ë²• 3: ì²´ì¸ ì•ˆì—ì„œ ì§ì ‘ ì‚¬ìš©

```python
chain = (
    prompt
    | llm
    | RunnableLambda(lambda x: x.upper())
    | parser
)
```

### 2. íƒ€ì… íŒíŠ¸ í™œìš©

```python
def process_text(text: str) -> str:
    """ëª…í™•í•œ íƒ€ì… íŒíŠ¸ë¡œ ê°€ë…ì„± í–¥ìƒ"""
    return text.strip().lower()

runnable = RunnableLambda(process_text)
```

### 3. ë³µì¡í•œ ë³€í™˜

```python
def transform_data(data: dict) -> dict:
    """ë”•ì…”ë„ˆë¦¬ ë³€í™˜"""
    return {
        "text": data.get("content", ""),
        "metadata": {
            "length": len(data.get("content", "")),
            "timestamp": data.get("timestamp")
        }
    }

transformer = RunnableLambda(transform_data)
```

---

## ì£¼ìš” í™œìš© ì‚¬ë¡€

### 1. ë°ì´í„° í˜•ì‹ ë³€í™˜ â­

**ê°€ì¥ ì¼ë°˜ì ì´ê³  ì¤‘ìš”í•œ ì‚¬ìš© ì‚¬ë¡€**

#### str â†’ dict ë³€í™˜

```python
# ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
def str_to_dict(text: str) -> dict:
    return {"text": text}

str_to_dict_runnable = RunnableLambda(str_to_dict)

chain = (
    summarizer                          # ì¶œë ¥: str
    | str_to_dict_runnable             # str â†’ {"text": str}
    | translator                        # ì…ë ¥: {"text"}
)
```

#### í‚¤ ì´ë¦„ ë³€ê²½

```python
# article â†’ text í‚¤ ë³€ê²½
def rename_key(data: dict) -> dict:
    return {"text": data.get("article", "")}

key_mapper = RunnableLambda(rename_key)

chain = (
    fetcher                            # ì¶œë ¥: {"article": "..."}
    | key_mapper                       # {"article"} â†’ {"text"}
    | processor                        # ì…ë ¥: {"text"}
)
```

#### Phase 5 ì˜ˆì œ 1ì—ì„œì˜ ì‹¤ì œ ì‚¬ìš©

```python
def map_to_text(output: str) -> dict:
    return {"text": output}

workflow = (
    summarizer                          # {article} â†’ str
    | RunnableLambda(map_to_text)      # str â†’ {text}
    | translator                        # {text} â†’ str
    | RunnableLambda(map_to_text)      # str â†’ {text}
    | keyword_extractor                 # {text} â†’ str
)
```

### 2. ë°ì´í„° ì „ì²˜ë¦¬

#### í…ìŠ¤íŠ¸ ì •ì œ

```python
def clean_text(data: dict) -> dict:
    """ê³µë°± ì œê±° ë° ì†Œë¬¸ì ë³€í™˜"""
    text = data["text"]
    cleaned = text.strip().lower()
    return {"text": cleaned}

cleaner = RunnableLambda(clean_text)

chain = (
    cleaner           # ì „ì²˜ë¦¬
    | summarizer      # ìš”ì•½
    | translator      # ë²ˆì—­
)
```

#### ë°ì´í„° ê²€ì¦

```python
def validate_input(data: dict) -> dict:
    """ì…ë ¥ ë°ì´í„° ê²€ì¦"""
    text = data.get("text", "")

    if not text or not text.strip():
        raise ValueError("í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")

    if len(text) < 10:
        raise ValueError("í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")

    return data

validator = RunnableLambda(validate_input)

chain = (
    validator         # ê²€ì¦
    | processor       # ì²˜ë¦¬
)
```

#### ë©”íƒ€ë°ì´í„° ì¶”ê°€

```python
def add_metadata(data: dict) -> dict:
    """ë©”íƒ€ë°ì´í„° ì¶”ê°€"""
    from datetime import datetime

    return {
        **data,
        "processed_at": datetime.now().isoformat(),
        "word_count": len(data["text"].split()),
        "char_count": len(data["text"])
    }

metadata_adder = RunnableLambda(add_metadata)

chain = (
    processor
    | metadata_adder   # ë©”íƒ€ë°ì´í„° ì¶”ê°€
    | saver
)
```

### 3. ë°ì´í„° í›„ì²˜ë¦¬

#### ê²°ê³¼ í¬ë§·íŒ…

```python
def format_result(text: str) -> str:
    """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…"""
    return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           ë¶„ì„ ê²°ê³¼                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
{text}
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

formatter = RunnableLambda(format_result)

chain = (
    analyzer
    | formatter        # í¬ë§·íŒ…
)
```

#### ê²°ê³¼ í†µí•©

```python
def merge_results(results: dict) -> str:
    """ë³‘ë ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ í†µí•©"""
    return f"""
ìš”ì•½: {results['summary']}
ê°ì •: {results['sentiment']}
í‚¤ì›Œë“œ: {results['keywords']}
"""

merger = RunnableLambda(merge_results)

chain = (
    RunnableParallel(
        summary=summarizer,
        sentiment=sentiment_analyzer,
        keywords=keyword_extractor
    )
    | merger          # ê²°ê³¼ í†µí•©
)
```

### 4. ë¡œê¹… ë° ë””ë²„ê¹…

#### ì¤‘ê°„ ê²°ê³¼ ì¶œë ¥

```python
def log_output(data):
    """ì¤‘ê°„ ê²°ê³¼ë¥¼ ë¡œê¹…í•˜ê³  ê·¸ëŒ€ë¡œ ì „ë‹¬"""
    print(f"ğŸ“Š ì¤‘ê°„ ê²°ê³¼: {data}")
    return data

logger = RunnableLambda(log_output)

chain = (
    step1
    | logger          # ë¡œê¹…
    | step2
    | logger          # ë¡œê¹…
    | step3
)
```

#### íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€

```python
import time

def log_with_timestamp(data):
    """íƒ€ì„ìŠ¤íƒ¬í”„ì™€ í•¨ê»˜ ë¡œê¹…"""
    timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] ë°ì´í„°: {data}")
    return data

timestamped_logger = RunnableLambda(log_with_timestamp)
```

#### ì¡°ê±´ë¶€ ë¡œê¹…

```python
def conditional_log(data, condition=lambda x: True):
    """ì¡°ê±´ì„ ë§Œì¡±í•  ë•Œë§Œ ë¡œê¹…"""
    if condition(data):
        print(f"âš ï¸  ì¡°ê±´ ì¶©ì¡±: {data}")
    return data

# ì‚¬ìš©
chain = (
    step1
    | RunnableLambda(lambda x: conditional_log(x, lambda d: len(d["text"]) > 100))
    | step2
)
```

### 5. ì¡°ê±´ë¶€ ë¡œì§

#### ê¸¸ì´ì— ë”°ë¥¸ ë¶„ê¸°

```python
def process_by_length(data: dict) -> dict:
    """í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬"""
    text = data["text"]

    if len(text) < 100:
        # ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ê·¸ëŒ€ë¡œ
        return data
    elif len(text) < 500:
        # ì¤‘ê°„ ê¸¸ì´ëŠ” ì•½ê°„ ìš”ì•½
        return {"text": text[:250] + "..."}
    else:
        # ê¸´ í…ìŠ¤íŠ¸ëŠ” ë§ì´ ìš”ì•½
        return {"text": text[:100] + "..."}

processor = RunnableLambda(process_by_length)

chain = (
    processor         # ì¡°ê±´ë¶€ ì²˜ë¦¬
    | translator
)
```

#### ì–¸ì–´ ê°ì§€

```python
def detect_and_route(data: dict) -> dict:
    """ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³  ì ì ˆí•œ ì²˜ë¦¬ ê²½ë¡œ ì„¤ì •"""
    text = data["text"]

    # ê°„ë‹¨í•œ ì–¸ì–´ ê°ì§€ (ì‹¤ì œë¡œëŠ” langdetect ë“± ì‚¬ìš©)
    if any(ord(char) > 127 for char in text[:100]):
        data["language"] = "non-english"
    else:
        data["language"] = "english"

    return data

language_router = RunnableLambda(detect_and_route)
```

### 6. ì—ëŸ¬ ì²˜ë¦¬

#### Try-Catch ë˜í¼

```python
def safe_process(data):
    """ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰"""
    try:
        # ìœ„í—˜í•œ ì‘ì—…
        result = risky_operation(data)
        return result
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        return {"error": str(e), "original": data}

safe_processor = RunnableLambda(safe_process)

chain = (
    safe_processor    # ì—ëŸ¬ ì²˜ë¦¬
    | next_step
)
```

#### Fallback íŒ¨í„´

```python
def with_fallback(primary_func, fallback_func):
    """ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ í•¨ìˆ˜ ì‹¤í–‰"""
    def wrapper(data):
        try:
            return primary_func(data)
        except Exception as e:
            print(f"âš ï¸  Primary ì‹¤íŒ¨, fallback ì‚¬ìš©: {e}")
            return fallback_func(data)
    return wrapper

# ì‚¬ìš©
processor = RunnableLambda(
    with_fallback(
        primary_process,
        simple_process
    )
)
```

---

## ì‹¤ì „ ì˜ˆì œ

### ì˜ˆì œ 1: ì™„ì „í•œ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```python
from langchain_core.runnables import RunnableLambda
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# LLM ì´ˆê¸°í™”
llm = ChatAnthropic(model="claude-3-haiku-20240307")

# 1. ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤
def clean_text(data: dict) -> dict:
    """í…ìŠ¤íŠ¸ ì •ì œ"""
    text = data["text"]
    cleaned = text.strip().lower()
    return {"text": cleaned}

def validate_length(data: dict) -> dict:
    """ê¸¸ì´ ê²€ì¦"""
    if len(data["text"]) < 10:
        raise ValueError("í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")
    return data

def add_metadata(data: dict) -> dict:
    """ë©”íƒ€ë°ì´í„° ì¶”ê°€"""
    from datetime import datetime
    return {
        **data,
        "timestamp": datetime.now().isoformat(),
        "length": len(data["text"])
    }

# 2. LLM ì²´ì¸
summarizer = (
    PromptTemplate.from_template("ìš”ì•½: {text}")
    | llm
    | StrOutputParser()
)

# 3. í›„ì²˜ë¦¬ í•¨ìˆ˜
def format_output(text: str) -> str:
    """ê²°ê³¼ í¬ë§·íŒ…"""
    return f"ğŸ“ ìš”ì•½ ê²°ê³¼:\n{text}"

# 4. ì „ì²´ íŒŒì´í”„ë¼ì¸
pipeline = (
    RunnableLambda(clean_text)         # ì •ì œ
    | RunnableLambda(validate_length)   # ê²€ì¦
    | RunnableLambda(add_metadata)      # ë©”íƒ€ë°ì´í„°
    | summarizer                         # ìš”ì•½
    | RunnableLambda(format_output)     # í¬ë§·íŒ…
)

# ì‹¤í–‰
result = pipeline.invoke({"text": "Your article here..."})
print(result)
```

### ì˜ˆì œ 2: ë³‘ë ¬ ì‹¤í–‰ í›„ í†µí•©

```python
from langchain_core.runnables import RunnableParallel, RunnableLambda

# ë³‘ë ¬ ë¶„ì„
parallel = RunnableParallel(
    summary=summarizer,
    keywords=keyword_extractor,
    sentiment=sentiment_analyzer
)

# ê²°ê³¼ í†µí•© í•¨ìˆ˜
def integrate_results(results: dict) -> dict:
    """ë³‘ë ¬ ë¶„ì„ ê²°ê³¼ í†µí•©"""
    return {
        "summary": results["summary"],
        "keywords": results["keywords"].split(", "),
        "sentiment": results["sentiment"],
        "analysis_complete": True
    }

# ìµœì¢… í¬ë§·íŒ…
def format_final(data: dict) -> str:
    """ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""
    return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           ë¶„ì„ ì™„ë£Œ                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

ğŸ“ ìš”ì•½:
{data['summary']}

ğŸ”‘ í‚¤ì›Œë“œ:
{', '.join(data['keywords'])}

ğŸ˜Š ê°ì •:
{data['sentiment']}

â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

# ì „ì²´ ì›Œí¬í”Œë¡œìš°
workflow = (
    parallel                             # ë³‘ë ¬ ë¶„ì„
    | RunnableLambda(integrate_results)  # í†µí•©
    | RunnableLambda(format_final)       # í¬ë§·íŒ…
)

result = workflow.invoke({"text": "Your article..."})
print(result)
```

### ì˜ˆì œ 3: ì¡°ê±´ë¶€ ë¼ìš°íŒ…

```python
def route_by_length(data: dict) -> dict:
    """ê¸¸ì´ì— ë”°ë¼ ì²˜ë¦¬ ê²½ë¡œ ì„¤ì •"""
    length = len(data["text"])

    if length < 100:
        data["route"] = "short"
    elif length < 500:
        data["route"] = "medium"
    else:
        data["route"] = "long"

    return data

def process_by_route(data: dict) -> str:
    """ê²½ë¡œì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬"""
    route = data["route"]
    text = data["text"]

    if route == "short":
        return f"ì§§ì€ í…ìŠ¤íŠ¸: {text}"
    elif route == "medium":
        return f"ì¤‘ê°„ í…ìŠ¤íŠ¸: {text[:100]}..."
    else:
        return f"ê¸´ í…ìŠ¤íŠ¸: {text[:50]}..."

# íŒŒì´í”„ë¼ì¸
pipeline = (
    RunnableLambda(route_by_length)      # ë¼ìš°íŒ…
    | RunnableLambda(process_by_route)   # ê²½ë¡œë³„ ì²˜ë¦¬
)

result = pipeline.invoke({"text": "Some text..."})
```

### ì˜ˆì œ 4: ìƒíƒœ ì¶”ì 

```python
def create_state_tracker():
    """ìƒíƒœë¥¼ ì¶”ì í•˜ëŠ” í•¨ìˆ˜ ìƒì„±"""
    state = {"count": 0, "total_length": 0}

    def track(data: dict) -> dict:
        state["count"] += 1
        state["total_length"] += len(data.get("text", ""))

        print(f"ì²˜ë¦¬ íšŸìˆ˜: {state['count']}")
        print(f"ì´ ê¸¸ì´: {state['total_length']}")

        return data

    return track

# ì‚¬ìš©
tracker = RunnableLambda(create_state_tracker())

pipeline = (
    tracker           # ìƒíƒœ ì¶”ì 
    | processor
    | tracker         # ë‹¤ì‹œ ì¶”ì 
)
```

---

## ê³ ê¸‰ íŒ¨í„´

### 1. í•¨ìˆ˜ í•©ì„± (Composition)

```python
def compose(*functions):
    """ì—¬ëŸ¬ í•¨ìˆ˜ë¥¼ í•˜ë‚˜ë¡œ í•©ì„±"""
    def composed(data):
        result = data
        for func in functions:
            result = func(result)
        return result
    return composed

# ì‚¬ìš©
cleaner = compose(
    lambda x: x.strip(),
    lambda x: x.lower(),
    lambda x: x.replace("\n", " ")
)

pipeline = (
    RunnableLambda(cleaner)
    | processor
)
```

### 2. ë°ì½”ë ˆì´í„° íŒ¨í„´

```python
def with_logging(func):
    """ë¡œê¹…ì„ ì¶”ê°€í•˜ëŠ” ë°ì½”ë ˆì´í„°"""
    def wrapper(data):
        print(f"[IN] {data}")
        result = func(data)
        print(f"[OUT] {result}")
        return result
    return wrapper

def with_timing(func):
    """ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•˜ëŠ” ë°ì½”ë ˆì´í„°"""
    import time
    def wrapper(data):
        start = time.time()
        result = func(data)
        elapsed = time.time() - start
        print(f"â±ï¸  ì‹¤í–‰ ì‹œê°„: {elapsed:.4f}ì´ˆ")
        return result
    return wrapper

# ì‚¬ìš©
@with_logging
@with_timing
def process(data):
    return data.upper()

pipeline = (
    RunnableLambda(process)
    | next_step
)
```

### 3. ìºì‹± íŒ¨í„´

```python
def with_cache(func):
    """ê²°ê³¼ë¥¼ ìºì‹±í•˜ëŠ” ë˜í¼"""
    cache = {}

    def wrapper(data):
        # ë”•ì…”ë„ˆë¦¬ë¥¼ í•´ì‹œ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        key = str(data)

        if key in cache:
            print("ğŸ’¾ ìºì‹œì—ì„œ ë°˜í™˜")
            return cache[key]

        print("ğŸ”„ ìƒˆë¡œ ê³„ì‚°")
        result = func(data)
        cache[key] = result
        return result

    return wrapper

# ì‚¬ìš©
cached_processor = RunnableLambda(with_cache(expensive_process))

pipeline = (
    cached_processor  # ìºì‹œ ì ìš©
    | next_step
)
```

### 4. ì¬ì‹œë„ íŒ¨í„´

```python
def with_retry(func, max_retries=3):
    """ì¬ì‹œë„ ë¡œì§ì„ ì¶”ê°€í•˜ëŠ” ë˜í¼"""
    import time

    def wrapper(data):
        for attempt in range(max_retries):
            try:
                return func(data)
            except Exception as e:
                if attempt == max_retries - 1:
                    raise
                print(f"âš ï¸  ì¬ì‹œë„ {attempt + 1}/{max_retries}")
                time.sleep(1 * (attempt + 1))  # ì§€ìˆ˜ ë°±ì˜¤í”„

    return wrapper

# ì‚¬ìš©
reliable_processor = RunnableLambda(with_retry(unstable_process, 3))

pipeline = (
    reliable_processor  # ì¬ì‹œë„ í¬í•¨
    | next_step
)
```

### 5. íŒŒì´í”„ë¼ì¸ ë¶„ê¸°

```python
def create_branch(condition_func, true_branch, false_branch):
    """ì¡°ê±´ì— ë”°ë¼ ë‹¤ë¥¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    def brancher(data):
        if condition_func(data):
            return true_branch.invoke(data)
        else:
            return false_branch.invoke(data)
    return brancher

# ì‚¬ìš©
is_long = lambda x: len(x.get("text", "")) > 1000

long_pipeline = summarizer | translator
short_pipeline = translator | keyword_extractor

brancher = RunnableLambda(
    create_branch(
        is_long,
        long_pipeline,
        short_pipeline
    )
)

pipeline = (
    preprocessor
    | brancher        # ì¡°ê±´ë¶€ ë¶„ê¸°
    | postprocessor
)
```

---

## ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­

### 1. ì˜¤ë²„í—¤ë“œ ì¸¡ì •

```python
import time

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def simple_process(x):
    return x.upper()

# ì¼ë°˜ í•¨ìˆ˜ í˜¸ì¶œ
start = time.time()
for i in range(100000):
    result = simple_process("hello")
time1 = time.time() - start

# RunnableLambda í˜¸ì¶œ
runnable = RunnableLambda(simple_process)
start = time.time()
for i in range(100000):
    result = runnable.invoke("hello")
time2 = time.time() - start

print(f"ì¼ë°˜ í•¨ìˆ˜: {time1:.4f}ì´ˆ")
print(f"RunnableLambda: {time2:.4f}ì´ˆ")
print(f"ì˜¤ë²„í—¤ë“œ: {((time2 - time1) / time1 * 100):.2f}%")

# ì¼ë°˜ì ìœ¼ë¡œ 1-5% ì •ë„ì˜ ì˜¤ë²„í—¤ë“œ
# LLM í˜¸ì¶œ ì‹œê°„ì— ë¹„í•˜ë©´ ë¬´ì‹œí•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€
```

### 2. ìµœì í™” íŒ

#### âœ… ì¢‹ì€ ì˜ˆ

```python
# ê°„ë‹¨í•œ ë³€í™˜ì€ ëŒë‹¤ ì‚¬ìš©
RunnableLambda(lambda x: x.upper())
RunnableLambda(lambda x: {"text": x})

# ë°˜ë³µë˜ëŠ” íŒ¨í„´ì€ í•¨ìˆ˜ë¡œ ì •ì˜
def to_dict(x):
    return {"text": x}

key_mapper = RunnableLambda(to_dict)
```

#### âš ï¸ ì£¼ì˜í•  ì 

```python
# ë³µì¡í•œ ë¡œì§ì€ ë³„ë„ í•¨ìˆ˜ë¡œ
def complex_processing(data):
    # ë§ì€ ì²˜ë¦¬...
    # 100ì¤„ ì´ìƒì˜ ì½”ë“œ
    return result

# ëŒë‹¤ë¡œ ì‘ì„±í•˜ì§€ ë§ ê²ƒ
# RunnableLambda(lambda x: ... 100 lines ...)  # âŒ

# ëª…í™•í•œ í•¨ìˆ˜ë¡œ ì‘ì„±
RunnableLambda(complex_processing)  # âœ…
```

### 3. ë©”ëª¨ë¦¬ ê´€ë¦¬

```python
# âŒ ë‚˜ìœ ì˜ˆ: í´ë¡œì €ë¡œ í° ë°ì´í„° ìº¡ì²˜
large_data = load_large_dataset()  # 1GB

def process_with_data(x):
    # large_dataê°€ ë©”ëª¨ë¦¬ì— ê³„ì† ìœ ì§€ë¨
    return lookup(large_data, x)

processor = RunnableLambda(process_with_data)

# âœ… ì¢‹ì€ ì˜ˆ: í•„ìš”í•  ë•Œë§Œ ë¡œë“œ
def process_efficiently(x):
    data = load_specific_data(x)  # í•„ìš”í•œ ë¶€ë¶„ë§Œ
    return lookup(data, x)

processor = RunnableLambda(process_efficiently)
```

---

## ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### âœ… ê¶Œì¥ ì‚¬í•­

#### 1. ëª…í™•í•œ í•¨ìˆ˜ ì´ë¦„

```python
# âŒ ë‚˜ìœ ì˜ˆ
f = RunnableLambda(lambda x: x.upper())

# âœ… ì¢‹ì€ ì˜ˆ
def uppercase_text(text: str) -> str:
    return text.upper()

uppercaser = RunnableLambda(uppercase_text)
```

#### 2. íƒ€ì… íŒíŠ¸ ì‚¬ìš©

```python
# âœ… íƒ€ì… íŒíŠ¸ë¡œ ëª…í™•ì„± í–¥ìƒ
def transform_data(data: dict) -> dict:
    """ë°ì´í„° ë³€í™˜ í•¨ìˆ˜

    Args:
        data: ì…ë ¥ ë”•ì…”ë„ˆë¦¬

    Returns:
        ë³€í™˜ëœ ë”•ì…”ë„ˆë¦¬
    """
    return {"text": data.get("content", "")}

transformer = RunnableLambda(transform_data)
```

#### 3. ë‹¨ì¼ ì±…ì„ ì›ì¹™

```python
# âŒ ë‚˜ìœ ì˜ˆ: ì—¬ëŸ¬ ì‘ì—…ì„ í•œ í•¨ìˆ˜ì—
def do_everything(data):
    cleaned = data.strip().lower()
    validated = validate(cleaned)
    enriched = add_metadata(validated)
    return enriched

# âœ… ì¢‹ì€ ì˜ˆ: ê° ì‘ì—…ì„ ë¶„ë¦¬
cleaner = RunnableLambda(lambda x: x.strip().lower())
validator = RunnableLambda(validate)
enricher = RunnableLambda(add_metadata)

pipeline = cleaner | validator | enricher
```

#### 4. ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜

```python
# âœ… ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
def create_key_mapper(from_key: str, to_key: str):
    """í‚¤ ì´ë¦„ì„ ë³€ê²½í•˜ëŠ” í•¨ìˆ˜ ìƒì„±"""
    def mapper(data: dict) -> dict:
        return {to_key: data.get(from_key, "")}
    return mapper

# ì—¬ëŸ¬ ê³³ì—ì„œ ì¬ì‚¬ìš©
article_to_text = RunnableLambda(create_key_mapper("article", "text"))
content_to_text = RunnableLambda(create_key_mapper("content", "text"))
```

#### 5. ì—ëŸ¬ ë©”ì‹œì§€ ëª…í™•í•˜ê²Œ

```python
def validate_input(data: dict) -> dict:
    """ì…ë ¥ ê²€ì¦"""
    if "text" not in data:
        raise ValueError("'text' í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")

    if not isinstance(data["text"], str):
        raise TypeError("'text'ëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤")

    if len(data["text"]) < 10:
        raise ValueError(
            f"í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (ìµœì†Œ 10ì, í˜„ì¬ {len(data['text'])}ì)"
        )

    return data

validator = RunnableLambda(validate_input)
```

### âš ï¸ í”¼í•´ì•¼ í•  íŒ¨í„´

#### 1. ë³µì¡í•œ ëŒë‹¤ í•¨ìˆ˜

```python
# âŒ ë‚˜ìœ ì˜ˆ: ì½ê¸° ì–´ë ¤ìš´ ëŒë‹¤
RunnableLambda(lambda x: {"text": x.get("content", "").strip().lower().replace("\n", " ") if x.get("content") else ""})

# âœ… ì¢‹ì€ ì˜ˆ: ëª…í™•í•œ í•¨ìˆ˜
def prepare_text(data: dict) -> dict:
    content = data.get("content", "")
    if not content:
        return {"text": ""}

    cleaned = content.strip().lower().replace("\n", " ")
    return {"text": cleaned}

preparer = RunnableLambda(prepare_text)
```

#### 2. ë¶€ì‘ìš©(Side Effects)ì´ ìˆëŠ” í•¨ìˆ˜

```python
# âš ï¸  ì£¼ì˜: ë¶€ì‘ìš©ì´ ìˆëŠ” í•¨ìˆ˜
def process_with_side_effect(data):
    # ì „ì—­ ë³€ìˆ˜ ìˆ˜ì •
    global counter
    counter += 1

    # íŒŒì¼ ì“°ê¸°
    with open("log.txt", "a") as f:
        f.write(str(data))

    return data

# âœ… ë” ë‚˜ì€ ë°©ë²•: ë¶€ì‘ìš©ì„ ëª…ì‹œì ìœ¼ë¡œ ì²˜ë¦¬
def process_safely(data):
    # ë¡œê¹…ì€ ë³„ë„ ì‹œìŠ¤í…œ ì‚¬ìš©
    logger.info(f"Processing: {data}")
    return data
```

#### 3. ìƒíƒœ ì˜ì¡´ì ì¸ í•¨ìˆ˜

```python
# âš ï¸  ì£¼ì˜: ì™¸ë¶€ ìƒíƒœì— ì˜ì¡´
external_config = {"mode": "production"}

def process_with_state(data):
    # ì™¸ë¶€ ìƒíƒœì— ì˜ì¡´ - ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥
    if external_config["mode"] == "production":
        return process_prod(data)
    else:
        return process_dev(data)

# âœ… ë” ë‚˜ì€ ë°©ë²•: ìƒíƒœë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
def create_processor(mode: str):
    def processor(data):
        if mode == "production":
            return process_prod(data)
        else:
            return process_dev(data)
    return processor

prod_processor = RunnableLambda(create_processor("production"))
```

---

## ì¼ë°˜ í•¨ìˆ˜ vs RunnableLambda ë¹„êµ

| í•­ëª© | ì¼ë°˜ í•¨ìˆ˜ | RunnableLambda |
|------|----------|----------------|
| **í˜¸ì¶œ ë°©ì‹** | `func(x)` | `runnable.invoke(x)` |
| **íŒŒì´í”„ ì—°ì‚°ì** | âŒ ë¶ˆê°€ | âœ… ê°€ëŠ¥ |
| **ë°°ì¹˜ ì²˜ë¦¬** | ìˆ˜ë™ êµ¬í˜„ | âœ… `.batch()` ì œê³µ |
| **ìŠ¤íŠ¸ë¦¬ë°** | ìˆ˜ë™ êµ¬í˜„ | âœ… `.stream()` ì œê³µ |
| **ë¹„ë™ê¸°** | `async def` í•„ìš” | âœ… `.ainvoke()` ì œê³µ |
| **ì²´ì¸ í†µí•©** | âŒ ì–´ë ¤ì›€ | âœ… ì™„ì „ í†µí•© |
| **ì—ëŸ¬ ì²˜ë¦¬** | ìˆ˜ë™ êµ¬í˜„ | ì²´ì¸ ë ˆë²¨ ì²˜ë¦¬ ê°€ëŠ¥ |
| **ë””ë²„ê¹…** | ì‰¬ì›€ | ì•½ê°„ ë³µì¡ |
| **ì„±ëŠ¥** | ë¹ ë¦„ | ì•½ê°„ ëŠë¦¼ (1-5%) |

### ì–¸ì œ ë¬´ì—‡ì„ ì‚¬ìš©í• ê¹Œ?

```python
# âœ… RunnableLambda ì‚¬ìš©
- LangChain ì²´ì¸ì—ì„œ ì‚¬ìš©
- íŒŒì´í”„ ì—°ì‚°ì í•„ìš”
- ë°°ì¹˜ ì²˜ë¦¬ í•„ìš”
- ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤ í•„ìš”

# âœ… ì¼ë°˜ í•¨ìˆ˜ ì‚¬ìš©
- ì²´ì¸ ì™¸ë¶€ì—ì„œ ì‚¬ìš©
- ë‹¨ìˆœ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
- ì„±ëŠ¥ì´ ë§¤ìš° ì¤‘ìš”
- í…ŒìŠ¤íŠ¸ ìš©ì´ì„± ì¤‘ìš”
```

---

## ì‹¤ì „ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: API ì‘ë‹µ ë³€í™˜

```python
def transform_api_response(response: dict) -> dict:
    """ì™¸ë¶€ API ì‘ë‹µì„ ë‚´ë¶€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    return {
        "text": response.get("data", {}).get("content", ""),
        "metadata": {
            "source": "external_api",
            "timestamp": response.get("timestamp"),
            "version": response.get("version", "1.0")
        }
    }

api_transformer = RunnableLambda(transform_api_response)

pipeline = (
    api_fetcher
    | api_transformer      # API ì‘ë‹µ ë³€í™˜
    | processor
)
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ë‹¤êµ­ì–´ ì²˜ë¦¬

```python
def detect_language(data: dict) -> dict:
    """ì–¸ì–´ ê°ì§€ ë° íƒœê¹…"""
    text = data["text"]

    # ê°„ë‹¨í•œ ì–¸ì–´ ê°ì§€
    if any('\u4e00' <= char <= '\u9fff' for char in text):
        lang = "zh"
    elif any('\u3040' <= char <= '\u309f' for char in text):
        lang = "ja"
    elif any('\uac00' <= char <= '\ud7a3' for char in text):
        lang = "ko"
    else:
        lang = "en"

    return {**data, "language": lang}

language_detector = RunnableLambda(detect_language)

pipeline = (
    language_detector      # ì–¸ì–´ ê°ì§€
    | language_router      # ì–¸ì–´ë³„ ì²˜ë¦¬
)
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: í’ˆì§ˆ í•„í„°ë§

```python
def filter_low_quality(data: dict) -> dict:
    """ì €í’ˆì§ˆ ë°ì´í„° í•„í„°ë§"""
    text = data.get("text", "")

    # í’ˆì§ˆ ì²´í¬
    quality_score = 0

    if len(text) >= 50:
        quality_score += 1

    if any(char.isalpha() for char in text):
        quality_score += 1

    if text.count(" ") >= 5:
        quality_score += 1

    data["quality_score"] = quality_score

    if quality_score < 2:
        raise ValueError(f"í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤ (ì ìˆ˜: {quality_score}/3)")

    return data

quality_filter = RunnableLambda(filter_low_quality)

pipeline = (
    fetcher
    | quality_filter       # í’ˆì§ˆ í•„í„°ë§
    | processor
)
```

---

## ë””ë²„ê¹… íŒ

### 1. ì¤‘ê°„ ê²°ê³¼ í™•ì¸

```python
def debug_print(label: str):
    """ë””ë²„ê¹…ìš© í”„ë¦°íŠ¸ í•¨ìˆ˜ ìƒì„±"""
    def printer(data):
        print(f"\n{'='*50}")
        print(f"[{label}]")
        print(f"{'='*50}")
        print(data)
        print(f"{'='*50}\n")
        return data
    return printer

pipeline = (
    step1
    | RunnableLambda(debug_print("Step 1 ê²°ê³¼"))
    | step2
    | RunnableLambda(debug_print("Step 2 ê²°ê³¼"))
    | step3
)
```

### 2. íƒ€ì… ê²€ì¦

```python
def type_checker(expected_type):
    """íƒ€ì…ì„ ê²€ì¦í•˜ëŠ” í•¨ìˆ˜ ìƒì„±"""
    def checker(data):
        if not isinstance(data, expected_type):
            raise TypeError(
                f"ì˜ˆìƒ íƒ€ì…: {expected_type}, "
                f"ì‹¤ì œ íƒ€ì…: {type(data)}"
            )
        return data
    return checker

pipeline = (
    step1
    | RunnableLambda(type_checker(dict))   # dict í™•ì¸
    | step2
    | RunnableLambda(type_checker(str))    # str í™•ì¸
    | step3
)
```

### 3. ë‹¨ê³„ë³„ ì‹œê°„ ì¸¡ì •

```python
import time

def time_logger(label: str):
    """ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•˜ëŠ” í•¨ìˆ˜ ìƒì„±"""
    def logger(data):
        start = time.time()
        # ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ë˜ ì‹œê°„ ì¸¡ì •
        elapsed = time.time() - start
        print(f"â±ï¸  [{label}] ì‹¤í–‰ ì‹œê°„: {elapsed:.4f}ì´ˆ")
        return data
    return logger

pipeline = (
    RunnableLambda(time_logger("ì‹œì‘"))
    | step1
    | RunnableLambda(time_logger("Step 1 ì™„ë£Œ"))
    | step2
    | RunnableLambda(time_logger("Step 2 ì™„ë£Œ"))
)
```

---

## ìš”ì•½

### RunnableLambdaì˜ í•µì‹¬

**ëª©ì **
- ì¼ë°˜ Python í•¨ìˆ˜ë¥¼ LangChainì˜ Runnable ì¸í„°í˜ì´ìŠ¤ë¡œ ë³€í™˜
- ì²´ì¸ì—ì„œ ì»¤ìŠ¤í…€ ë¡œì§ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” "ì ‘ì°©ì œ" ì—­í• 

**ì£¼ìš” ì¥ì **
- âœ… íŒŒì´í”„ ì—°ì‚°ì (`|`) í˜¸í™˜
- âœ… ë°°ì¹˜ ì²˜ë¦¬ (`.batch()`) ì§€ì›
- âœ… ìŠ¤íŠ¸ë¦¬ë° (`.stream()`) ì§€ì›
- âœ… ë¹„ë™ê¸° (`.ainvoke()`) ì§€ì›
- âœ… ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤

**ì£¼ìš” ì‚¬ìš© ì‚¬ë¡€**
1. ë°ì´í„° í˜•ì‹ ë³€í™˜ (str â†” dict)
2. ì „ì²˜ë¦¬ (ì •ì œ, ê²€ì¦, ë©”íƒ€ë°ì´í„° ì¶”ê°€)
3. í›„ì²˜ë¦¬ (í¬ë§·íŒ…, í†µí•©)
4. ë¡œê¹… ë° ë””ë²„ê¹…
5. ì¡°ê±´ë¶€ ë¡œì§
6. ì—ëŸ¬ ì²˜ë¦¬

**ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤**
- âœ… ëª…í™•í•œ í•¨ìˆ˜ ì´ë¦„ ì‚¬ìš©
- âœ… íƒ€ì… íŒíŠ¸ ì¶”ê°€
- âœ… ë‹¨ì¼ ì±…ì„ ì›ì¹™ ì¤€ìˆ˜
- âœ… ì¬ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ ì„¤ê³„
- âš ï¸  ë³µì¡í•œ ëŒë‹¤ í•¨ìˆ˜ ì§€ì–‘
- âš ï¸  ë¶€ì‘ìš© ìµœì†Œí™”

### ê¸°ë³¸ íŒ¨í„´ ì •ë¦¬

```python
# 1. í‚¤ ë§¤í•‘
RunnableLambda(lambda x: {"text": x})

# 2. ì „ì²˜ë¦¬
RunnableLambda(lambda x: preprocess(x))

# 3. í›„ì²˜ë¦¬
RunnableLambda(lambda x: format_output(x))

# 4. ë¡œê¹…
RunnableLambda(lambda x: print(x) or x)

# 5. ê²€ì¦
RunnableLambda(lambda x: validate(x))
```

---

## ì°¸ê³  ìë£Œ

- [LangChain ê³µì‹ ë¬¸ì„œ - Runnable](https://python.langchain.com/docs/expression_language/interface/)
- [LangChain ê³µì‹ ë¬¸ì„œ - RunnableLambda](https://python.langchain.com/docs/expression_language/primitives/lambda/)
- Phase 5 ì˜ˆì œ ì½”ë“œ ì°¸ê³ 

---

**RunnableLambdaëŠ” LangChain ì²´ì¸ì˜ ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤. ì ì ˆíˆ ì‚¬ìš©í•˜ë©´ ìœ ì—°í•˜ê³  ê°•ë ¥í•œ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!** ğŸš€
