"""
Phase 5 - ì˜ˆì œ 3: ìˆœì°¨ + ë³‘ë ¬ ì¡°í•© ì›Œí¬í”Œë¡œìš°

ëª©í‘œ:
- ìˆœì°¨ ì‹¤í–‰ê³¼ ë³‘ë ¬ ì‹¤í–‰ì„ ì¡°í•©í•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°
- ì „ì²˜ë¦¬ â†’ ë³‘ë ¬ ë¶„ì„ â†’ ê²°ê³¼ í†µí•© íŒ¨í„´
- ì‹¤ì „ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” íŒŒì´í”„ë¼ì¸ êµ¬ì¡°
"""

from dotenv import load_dotenv
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableParallel, RunnableLambda, RunnablePassthrough

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# LLM ì´ˆê¸°í™”
llm = ChatAnthropic(
    model="claude-3-haiku-20240307",
    temperature=0
)

print("=" * 70)
print("Phase 5 - ì˜ˆì œ 3: ìˆœì°¨ + ë³‘ë ¬ ì¡°í•© ì›Œí¬í”Œë¡œìš°")
print("=" * 70)

# ============================================================================
# 1ë‹¨ê³„: ì „ì²˜ë¦¬ ì²´ì¸ (ìˆœì°¨)
# ============================================================================

print("\n[1ë‹¨ê³„] ì „ì²˜ë¦¬ ì²´ì¸ ì •ì˜\n")

# ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤
def clean_text(data: dict) -> dict:
    """í…ìŠ¤íŠ¸ ì •ì œ: ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜"""
    article = data["article"]
    cleaned = article.strip().lower()
    print(f"   ğŸ§¹ í…ìŠ¤íŠ¸ ì •ì œ ì™„ë£Œ (ê¸¸ì´: {len(cleaned)} ë¬¸ì)")
    return {"article": cleaned}

def extract_sentences(data: dict) -> dict:
    """ë¬¸ì¥ ë¶„ë¦¬"""
    article = data["article"]
    sentences = [s.strip() for s in article.split('.') if s.strip()]
    sentence_count = len(sentences)
    print(f"   ğŸ“„ ë¬¸ì¥ ë¶„ë¦¬ ì™„ë£Œ ({sentence_count}ê°œ ë¬¸ì¥)")
    return {"article": data["article"], "sentence_count": sentence_count}

# ì „ì²˜ë¦¬ ì²´ì¸
preprocessing = (
    RunnableLambda(clean_text)
    | RunnableLambda(extract_sentences)
)

print("âœ… ì „ì²˜ë¦¬ ì²´ì¸ ìƒì„±:")
print("""
    [clean_text] â†’ [extract_sentences]

    1. ê³µë°± ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
    2. ë¬¸ì¥ ë¶„ë¦¬ ë° ê°œìˆ˜ ì¹´ìš´íŠ¸
""")

# ============================================================================
# 2ë‹¨ê³„: ë³‘ë ¬ ë¶„ì„ ì²´ì¸
# ============================================================================

print("\n" + "=" * 70)
print("[2ë‹¨ê³„] ë³‘ë ¬ ë¶„ì„ ì²´ì¸ ì •ì˜")
print("=" * 70)

# ë¶„ì„ 1: ìš”ì•½
summarizer = (
    PromptTemplate.from_template(
        "ë‹¤ìŒ ì˜ë¬¸ ê¸°ì‚¬ë¥¼ 3ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{article}"
    )
    | llm
    | StrOutputParser()
)

# ë¶„ì„ 2: ê°ì • ë¶„ì„
sentiment_analyzer = (
    PromptTemplate.from_template(
        "ë‹¤ìŒ ì˜ë¬¸ ê¸°ì‚¬ì˜ ì „ì²´ì ì¸ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš” (ê¸ì •ì /ì¤‘ë¦½ì /ë¶€ì •ì  ì¤‘ í•˜ë‚˜):\n\n{article}"
    )
    | llm
    | StrOutputParser()
)

# ë¶„ì„ 3: ì£¼ì œ ë¶„ë¥˜
topic_classifier = (
    PromptTemplate.from_template(
        "ë‹¤ìŒ ì˜ë¬¸ ê¸°ì‚¬ì˜ ì£¼ì œë¥¼ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš” (ì˜ˆ: Technology, Health, Politics):\n\n{article}"
    )
    | llm
    | StrOutputParser()
)

# ë¶„ì„ 4: í‚¤ì›Œë“œ ì¶”ì¶œ
keyword_extractor = (
    PromptTemplate.from_template(
        "ë‹¤ìŒ ì˜ë¬¸ ê¸°ì‚¬ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ 3ê°œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„):\n\n{article}"
    )
    | llm
    | StrOutputParser()
)

# ë³‘ë ¬ ë¶„ì„
parallel_analysis = RunnableParallel(
    summary=summarizer,
    sentiment=sentiment_analyzer,
    topic=topic_classifier,
    keywords=keyword_extractor,
    metadata=RunnablePassthrough()  # ì›ë³¸ ë°ì´í„° ë³´ì¡´
)

print("""
âœ… ë³‘ë ¬ ë¶„ì„ ì²´ì¸ ìƒì„±:

                 â”Œâ†’ [summarizer] â†’ summary
                 â”‚
                 â”¼â†’ [sentiment_analyzer] â†’ sentiment
    ì „ì²˜ë¦¬ ê²°ê³¼ â†’ â”‚
                 â”¼â†’ [topic_classifier] â†’ topic
                 â”‚
                 â”¼â†’ [keyword_extractor] â†’ keywords
                 â”‚
                 â””â†’ [RunnablePassthrough] â†’ metadata

    ì¶œë ¥: {
        "summary": "...",
        "sentiment": "...",
        "topic": "...",
        "keywords": "...",
        "metadata": {ì›ë³¸ ë°ì´í„°}
    }
""")

# ============================================================================
# 3ë‹¨ê³„: ê²°ê³¼ í†µí•© ì²´ì¸ (ìˆœì°¨)
# ============================================================================

print("\n" + "=" * 70)
print("[3ë‹¨ê³„] ê²°ê³¼ í†µí•© ì²´ì¸ ì •ì˜")
print("=" * 70)

def integrate_results(analysis_results: dict) -> dict:
    """ë³‘ë ¬ ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë³´ê³ ì„œë¡œ í†µí•©"""
    print("\n   ğŸ“Š ë¶„ì„ ê²°ê³¼ í†µí•© ì¤‘...")

    report = {
        "summary": analysis_results["summary"],
        "sentiment": analysis_results["sentiment"],
        "topic": analysis_results["topic"],
        "keywords": analysis_results["keywords"],
        "sentence_count": analysis_results["metadata"].get("sentence_count", 0),
        "article_length": len(analysis_results["metadata"]["article"])
    }

    print("   âœ… í†µí•© ì™„ë£Œ!")
    return report

def format_final_report(report: dict) -> str:
    """ìµœì¢… ë³´ê³ ì„œ í¬ë§·íŒ…"""
    return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     ğŸ“Š ê¸°ì‚¬ ë¶„ì„ ìµœì¢… ë³´ê³ ì„œ                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

ğŸ“ ìš”ì•½:
{report['summary']}

ğŸ˜Š ê°ì • ë¶„ì„:
{report['sentiment']}

ğŸ·ï¸  ì£¼ì œ ë¶„ë¥˜:
{report['topic']}

ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ:
{report['keywords']}

ğŸ“ˆ ë©”íƒ€ë°ì´í„°:
- ì´ ë¬¸ì¥ ìˆ˜: {report['sentence_count']}ê°œ
- ê¸°ì‚¬ ê¸¸ì´: {report['article_length']}ì

â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

# í†µí•© ì²´ì¸
integration = (
    RunnableLambda(integrate_results)
    | RunnableLambda(format_final_report)
)

print("""
âœ… ê²°ê³¼ í†µí•© ì²´ì¸ ìƒì„±:

    [integrate_results] â†’ [format_final_report]

    1. ë³‘ë ¬ ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬ë¡œ í†µí•©
    2. ìµœì¢… ë³´ê³ ì„œ í¬ë§·íŒ…
""")

# ============================================================================
# 4ë‹¨ê³„: ì „ì²´ ì›Œí¬í”Œë¡œìš° êµ¬ì„±
# ============================================================================

print("\n" + "=" * 70)
print("[4ë‹¨ê³„] ì „ì²´ ì›Œí¬í”Œë¡œìš° êµ¬ì„±")
print("=" * 70)

# ì „ì²´ ì›Œí¬í”Œë¡œìš°: ì „ì²˜ë¦¬ â†’ ë³‘ë ¬ ë¶„ì„ â†’ ê²°ê³¼ í†µí•©
complete_workflow = (
    preprocessing       # ìˆœì°¨ 1: ì „ì²˜ë¦¬
    | parallel_analysis # ë³‘ë ¬: ë‹¤ì¤‘ ë¶„ì„
    | integration       # ìˆœì°¨ 2: ê²°ê³¼ í†µí•©
)

print("""
âœ… ì „ì²´ ì›Œí¬í”Œë¡œìš°:

    ì…ë ¥ ({article})
       â†“
    [ì „ì²˜ë¦¬] (ìˆœì°¨)
       â”œâ†’ clean_text
       â””â†’ extract_sentences
       â†“
    {article, sentence_count}
       â†“
              â”Œâ†’ [summarizer]
              â”¼â†’ [sentiment_analyzer]
    [ë³‘ë ¬ ë¶„ì„] â”¼â†’ [topic_classifier]
              â”¼â†’ [keyword_extractor]
              â””â†’ [metadata ë³´ì¡´]
       â†“
    {summary, sentiment, topic, keywords, metadata}
       â†“
    [ê²°ê³¼ í†µí•©] (ìˆœì°¨)
       â”œâ†’ integrate_results
       â””â†’ format_final_report
       â†“
    ìµœì¢… ë³´ê³ ì„œ (í¬ë§·ëœ ë¬¸ìì—´)

ìˆœì°¨ â†’ ë³‘ë ¬ â†’ ìˆœì°¨ íŒ¨í„´!
""")

# ============================================================================
# 5ë‹¨ê³„: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
# ============================================================================

print("\n" + "=" * 70)
print("[5ë‹¨ê³„] ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰")
print("=" * 70)

# í…ŒìŠ¤íŠ¸ ë°ì´í„°
article = """
Artificial Intelligence (AI) is revolutionizing the way we live and work.
From healthcare to finance, AI technologies are being integrated into various
sectors, enhancing efficiency and decision-making processes. Machine learning
algorithms can now analyze vast amounts of data in seconds, identifying patterns
that would take humans years to discover. However, ethical concerns about AI,
such as privacy and job displacement, continue to be debated by experts worldwide.
As we move forward, it is crucial to develop AI responsibly, ensuring it benefits
humanity as a whole.
"""

print("\nğŸ“„ ì…ë ¥ ê¸°ì‚¬:")
print("-" * 70)
print(article.strip())
print("-" * 70)

print("\nâ³ ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘...\n")
print("ğŸ”„ 1ë‹¨ê³„: ì „ì²˜ë¦¬ ì‹¤í–‰...")

# ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
final_report = complete_workflow.invoke({"article": article})

print("\n" + "=" * 70)
print("âœ… ìµœì¢… ë³´ê³ ì„œ")
print("=" * 70)

print(final_report)

# ============================================================================
# 6ë‹¨ê³„: ê° ë‹¨ê³„ë³„ ì‹¤í–‰ (ë””ë²„ê¹…)
# ============================================================================

print("\n" + "=" * 70)
print("[6ë‹¨ê³„] ê° ë‹¨ê³„ë³„ ì‹¤í–‰ (ë””ë²„ê¹…)")
print("=" * 70)

print("\n1ï¸âƒ£ ì „ì²˜ë¦¬ ë‹¨ê³„:")
print("-" * 70)
preprocessed = preprocessing.invoke({"article": article})
print(f"ê²°ê³¼: {preprocessed}")

print("\n2ï¸âƒ£ ë³‘ë ¬ ë¶„ì„ ë‹¨ê³„:")
print("-" * 70)
analysis_results = parallel_analysis.invoke(preprocessed)
print("ê²°ê³¼:")
for key, value in analysis_results.items():
    if key != "metadata":
        print(f"  {key}: {value}")

print("\n3ï¸âƒ£ ê²°ê³¼ í†µí•© ë‹¨ê³„:")
print("-" * 70)
integrated = integration.invoke(analysis_results)
print("ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")

# ============================================================================
# í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸
# ============================================================================

print("\n" + "=" * 70)
print("ğŸ“š í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸")
print("=" * 70)

print("""
1ï¸âƒ£ ìˆœì°¨ + ë³‘ë ¬ ì¡°í•©
   - ì „ì²˜ë¦¬: ìˆœì°¨ ì‹¤í–‰ (ë‹¨ê³„ë³„ ì˜ì¡´ì„±)
   - ë¶„ì„: ë³‘ë ¬ ì‹¤í–‰ (ë…ë¦½ì  ì‘ì—…)
   - í†µí•©: ìˆœì°¨ ì‹¤í–‰ (ê²°ê³¼ ê²°í•©)

2ï¸âƒ£ RunnablePassthrough
   - ë³‘ë ¬ ì‹¤í–‰ ì‹œ ì›ë³¸ ë°ì´í„° ë³´ì¡´
   - metadataë¡œ ì›ë³¸ ì •ë³´ ìœ ì§€
   - ë‚˜ì¤‘ì— ì°¸ì¡° ê°€ëŠ¥

3ï¸âƒ£ ë”•ì…”ë„ˆë¦¬ íë¦„
   - ê° ë‹¨ê³„ê°€ ë”•ì…”ë„ˆë¦¬ë¥¼ ì£¼ê³ ë°›ìŒ
   - í‚¤ ì´ë¦„ìœ¼ë¡œ ë°ì´í„° ì¶”ì 
   - ìœ ì—°í•œ ë°ì´í„° ê´€ë¦¬

4ï¸âƒ£ ì‹¤ì „ íŒ¨í„´
   - ì „ì²˜ë¦¬ â†’ ë³‘ë ¬ ë¶„ì„ â†’ í†µí•©
   - ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” êµ¬ì¡°
   - ì„±ëŠ¥ê³¼ ê°€ë…ì„± ëª¨ë‘ í™•ë³´

5ï¸âƒ£ ë””ë²„ê¹… ìš©ì´
   - ê° ë‹¨ê³„ë¥¼ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
   - ì¤‘ê°„ ê²°ê³¼ í™•ì¸ ê°€ëŠ¥
   - ë¬¸ì œ ë°œìƒ ì‹œ ì›ì¸ íŒŒì•… ì‰¬ì›€
""")

# ============================================================================
# ì‹¤ì „ í™œìš© íŒ¨í„´
# ============================================================================

print("\n" + "=" * 70)
print("ğŸ”§ ì‹¤ì „ í™œìš© íŒ¨í„´")
print("=" * 70)

print("""
íŒ¨í„´ 1: ë°ì´í„° ìˆ˜ì§‘ â†’ ë¶„ì„ â†’ ë³´ê³ ì„œ
workflow = (
    data_collector          # ìˆœì°¨: ë°ì´í„° ìˆ˜ì§‘
    | RunnableParallel(     # ë³‘ë ¬: ë‹¤ì–‘í•œ ë¶„ì„
        stats=statistics,
        viz=visualization,
        insights=insight_generator
    )
    | report_generator      # ìˆœì°¨: ë³´ê³ ì„œ ìƒì„±
)

íŒ¨í„´ 2: ê²€ì¦ â†’ ì²˜ë¦¬ â†’ ì €ì¥
workflow = (
    validator               # ìˆœì°¨: ë°ì´í„° ê²€ì¦
    | RunnableParallel(     # ë³‘ë ¬: ì—¬ëŸ¬ ì²˜ë¦¬
        process_a=processor_a,
        process_b=processor_b
    )
    | saver                 # ìˆœì°¨: ê²°ê³¼ ì €ì¥
)

íŒ¨í„´ 3: ì „ì²˜ë¦¬ â†’ ë‹¤ì¤‘ ëª¨ë¸ â†’ ì•™ìƒë¸”
workflow = (
    preprocessor            # ìˆœì°¨: ì „ì²˜ë¦¬
    | RunnableParallel(     # ë³‘ë ¬: ì—¬ëŸ¬ ëª¨ë¸
        gpt4=gpt4_chain,
        claude=claude_chain,
        gemini=gemini_chain
    )
    | ensemble              # ìˆœì°¨: ê²°ê³¼ ì•™ìƒë¸”
)

íŒ¨í„´ 4: ì›ë³¸ ë³´ì¡´ + ë³€í™˜
workflow = (
    RunnableParallel(
        original=RunnablePassthrough(),
        transformed=transformer
    )
    | comparator            # ì›ë³¸ê³¼ ë³€í™˜ ê²°ê³¼ ë¹„êµ
)
""")

# ============================================================================
# ì„±ëŠ¥ ìµœì í™” íŒ
# ============================================================================

print("\n" + "=" * 70)
print("âš¡ ì„±ëŠ¥ ìµœì í™” íŒ")
print("=" * 70)

print("""
1ï¸âƒ£ ë³‘ë ¬ ì‹¤í–‰ ìµœëŒ€í™”
   - ë…ë¦½ì ì¸ ì‘ì—…ì€ ìµœëŒ€í•œ ë³‘ë ¬ë¡œ
   - LLM í˜¸ì¶œì´ ë§ì„ìˆ˜ë¡ íš¨ê³¼ í¼
   - ì˜ˆ: 4ê°œ ì‘ì—… ë³‘ë ¬ â†’ ì•½ 4ë°° ë¹ ë¦„

2ï¸âƒ£ ë¶ˆí•„ìš”í•œ ìˆœì°¨ ì œê±°
   - ì˜ì¡´ì„± ì—†ëŠ” ì‘ì—…ì€ ë³‘ë ¬ë¡œ ì „í™˜
   - ì˜ˆ: "ìš”ì•½ í›„ í‚¤ì›Œë“œ" â†’ "ìš”ì•½ | í‚¤ì›Œë“œ" (ë³‘ë ¬ ê°€ëŠ¥)

3ï¸âƒ£ ë°ì´í„° ì „ë‹¬ ìµœì†Œí™”
   - í•„ìš”í•œ ë°ì´í„°ë§Œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬
   - í° ë°ì´í„°ëŠ” RunnablePassthrough í™œìš©

4ï¸âƒ£ ìºì‹± í™œìš©
   - ê°™ì€ ì…ë ¥ì— ëŒ€í•œ ê²°ê³¼ ìºì‹±
   - LangChain ìºì‹± ê¸°ëŠ¥ í™œìš©
   - ë°˜ë³µ í˜¸ì¶œ ë¹„ìš© ì ˆê°

5ï¸âƒ£ ë°°ì¹˜ ì²˜ë¦¬
   - ì—¬ëŸ¬ ì…ë ¥ì„ í•œ ë²ˆì— ì²˜ë¦¬
   - workflow.batch([input1, input2, ...])
   - ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ìœ ìš©
""")

# ============================================================================
# ë‹¤ìŒ ë‹¨ê³„
# ============================================================================

print("\n" + "=" * 70)
print("â¡ï¸  ë‹¤ìŒ ë‹¨ê³„")
print("=" * 70)

print("""
ì˜ˆì œ 4ì—ì„œëŠ”:
- ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤: ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ì„ ì‹œìŠ¤í…œ
- ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§
- ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
- í”„ë¡œë•ì…˜ ìˆ˜ì¤€ì˜ ì›Œí¬í”Œë¡œìš°

ì˜ˆì œ 1: ìˆœì°¨ (A â†’ B â†’ C)
ì˜ˆì œ 2: ë³‘ë ¬ (A â†’ [B1, B2, B3])
ì˜ˆì œ 3: ì¡°í•© (A â†’ [B1, B2] â†’ C)
ì˜ˆì œ 4: ì‹¤ì „ (ëª¨ë“  íŒ¨í„´ + ì—ëŸ¬ ì²˜ë¦¬ + ë¡œê¹…)
""")

print("\n" + "=" * 70)
print("âœ… ì˜ˆì œ 3 ì™„ë£Œ!")
print("=" * 70)
